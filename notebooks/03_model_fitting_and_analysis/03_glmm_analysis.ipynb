{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLMM Analysis\n",
    "\n",
    "**Important ðŸš¨:** If only the demo data for the most common nine species is used, the results produced for all 52 species will naturally be different from the display items in the publication.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../../src\")\n",
    "from imports import *\n",
    "from datetime import datetime\n",
    "\n",
    "init_notebook()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fx(df, change):\n",
    "    if change in [\"warmer\", \"cooler\"]:\n",
    "        values = df.query(\"change_temp_all == @change\")[\"pval_temp\"]\n",
    "        mean = values.mean()\n",
    "    else:\n",
    "        values = df.query(\"change_spei_all == @change\")[\"pval_spei\"]\n",
    "        mean = values.mean()\n",
    "\n",
    "    # print(f\"Mean p-value for {change}: {mean:.2f}\")\n",
    "    ax, fig = plt.subplots(figsize=(3, 3))\n",
    "    sns.histplot(values, kde=True, bins=20)\n",
    "    # Add legend\n",
    "    plt.legend([f\"{change} mean: {mean:.2f}\"])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_var_and_val(df_tmp, response_var, var_pval_threshold=0.05, group_threshold=0.6):\n",
    "\n",
    "    pvar = f\"pval_{response_var}\"\n",
    "    # df_tmp = df_tmp[df_tmp[pvar] < var_pval_threshold]\n",
    "    # display(df_tmp)\n",
    "\n",
    "    df_tmp = (\n",
    "        df_tmp[f\"response_{response_var}\"]\n",
    "        .value_counts(normalize=True)\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    ipattern = df_tmp.index[0]\n",
    "    ivalue = df_tmp.values[0]\n",
    "    if ivalue < group_threshold:\n",
    "        ipattern = \"ns\"\n",
    "\n",
    "    return ipattern, ivalue\n",
    "\n",
    "\n",
    "def plot_pattern_dist(df_in, var_in, dir_patterns=None):\n",
    "    # Sum up runs per group\n",
    "    df_in = (\n",
    "        df_in.groupby(var_in).agg(group_size_rel=(\"group_size\", \"sum\")).reset_index()\n",
    "    )\n",
    "    # Take percentage and turn into int\n",
    "    df_in[\"group_size_rel\"] = (\n",
    "        df_in[\"group_size_rel\"] / df_in[\"group_size_rel\"].sum() * 100\n",
    "    )\n",
    "    df_in[\"group_size_rel\"] = df_in[\"group_size_rel\"].round(0)\n",
    "    df_in[\"group_size_rel\"] = df_in[\"group_size_rel\"].astype(int)\n",
    "    # Sort by percentage\n",
    "    df_in = df_in.sort_values(\"group_size_rel\", ascending=True)\n",
    "    # Add percentage to label\n",
    "    df_in[\"change_simple\"] = df_in[var_in]\n",
    "    df_in[var_in] = df_in[var_in] + \" (\" + df_in[\"group_size_rel\"].astype(str) + \"%)\"\n",
    "    # Plot it\n",
    "    df_in = df_in.sort_values(\"group_size_rel\", ascending=False).reset_index(drop=True)\n",
    "    # display(df_in)\n",
    "    return df_in\n",
    "    # df_in.plot(kind=\"barh\", x=var_in, y=\"group_size_rel\", color=\"grey\", legend=False)\n",
    "    # plt.xlabel(\"Share of all runs (%)\")\n",
    "    # plt.ylabel(\"\")\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig(f\"{dir_patterns}/change_counts_before_merging_unclear_{var_in}.png\")\n",
    "    # plt.show()\n",
    "    # plt.close()\n",
    "\n",
    "\n",
    "def plot_bars_dataset_pattern(\n",
    "    patterns_merged,\n",
    "    all_dfs,\n",
    "    all_or_top9=\"all\",\n",
    "    color_temp=\"#77422C\",\n",
    "    color_spei=\"#D1A289\",\n",
    "    color_rest=\"lightgrey\",\n",
    "    color_wd=\"#B2182B\",  # Original: \"#B2182B\"\n",
    "    color_ww=\"#2166AC\",  # Original: \"#2166AC\"\n",
    "    color_other=\"lightgrey\",\n",
    "    color_cd=\"lightgrey\",  # Original: \"#EF8A62\",\n",
    "    color_cw=\"lightgrey\",  # Original: \"#67A9CF\",\n",
    "    ytick_labels=None,\n",
    "    left_ylim=60,\n",
    "    base_fontsize=12,\n",
    "    filepath=None,\n",
    "):\n",
    "    # Plot\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 5))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # ! Position of temp and cwb in the dataframe\n",
    "    if all_or_top9 == \"top9\":\n",
    "        pos_temp = 5\n",
    "        pos_spei = 6\n",
    "    elif all_or_top9 == \"all\":\n",
    "        pos_temp = 5\n",
    "        pos_spei = 3\n",
    "\n",
    "    ax_dataset_boxplot(\n",
    "        axs[0],\n",
    "        all_dfs,\n",
    "        all_dfs.columns[2:].tolist(),\n",
    "        base_fontsize,\n",
    "        pos_spei=pos_spei,\n",
    "        pos_temp=pos_temp,\n",
    "        color_spei=color_spei,\n",
    "        color_temp=color_temp,\n",
    "        color_rest=color_rest,\n",
    "        all_or_top9=all_or_top9,\n",
    "    )\n",
    "    axs[0].set_xlim(0, left_ylim)\n",
    "\n",
    "    # ax_dataset_boxplot(\n",
    "    #     axs[0],\n",
    "    #     all_dfs,\n",
    "    #     imps,\n",
    "    #     base_fontsize,\n",
    "    #     color_spei=color_spei,\n",
    "    #     color_temp=color_temp,\n",
    "    #     color_rest=color_rest,\n",
    "    #     all_or_top9=all_or_top9,\n",
    "    # )\n",
    "\n",
    "    # Barplot for patterns\n",
    "    sns.barplot(\n",
    "        data=patterns_merged,\n",
    "        x=\"group_size_rel\",\n",
    "        y=\"change_simple\",\n",
    "        hue=\"change_simple\",\n",
    "        palette=[\n",
    "            color_temp,\n",
    "            color_temp,\n",
    "            color_temp,\n",
    "            color_spei,\n",
    "            color_spei,\n",
    "            color_spei,\n",
    "            color_wd,\n",
    "            color_ww,\n",
    "            color_other,\n",
    "            color_cd,\n",
    "            color_cw,\n",
    "        ],\n",
    "        orient=\"h\",\n",
    "        height=0.5,\n",
    "        dodge=False,\n",
    "        edgecolor=\"black\",\n",
    "        # hue=\"response_spei\",\n",
    "        # palette=[\n",
    "        #     \"#B2182B\",\n",
    "        #     \"#2166AC\",\n",
    "        #     \"grey\",\n",
    "        # ],\n",
    "        ax=axs[1],\n",
    "    )\n",
    "\n",
    "    # Add values to end of bars\n",
    "    for i in range(len(patterns_merged)):\n",
    "        axs[1].text(\n",
    "            patterns_merged.loc[i, \"group_size_rel\"] + 1,\n",
    "            i + -0.1,\n",
    "            # f\"{patterns_merged.loc[i, 'group_size_rel']} %\",\n",
    "            f\"{patterns_merged.loc[i, 'group_size_rel']} % (sign: {patterns_merged.loc[i, 'perc_sign'].round(0).astype(int)}%)\",\n",
    "            va=\"center\",\n",
    "            fontsize=base_fontsize * 0.9,\n",
    "        )\n",
    "\n",
    "    # Add horizontal lines\n",
    "    axs[1].axhline(2.35, color=\"black\", linewidth=1)\n",
    "    axs[1].axhline(5.35, color=\"black\", linewidth=1)\n",
    "\n",
    "    # Add text\n",
    "    axs[1].text(\n",
    "        95,\n",
    "        2,\n",
    "        \"Temperature\\nanomaly\",\n",
    "        ha=\"right\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=base_fontsize * 1,\n",
    "    )\n",
    "    axs[1].text(\n",
    "        95,\n",
    "        5,\n",
    "        \"CWB anomaly\",\n",
    "        ha=\"right\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=base_fontsize * 1,\n",
    "    )\n",
    "    axs[1].text(\n",
    "        95,\n",
    "        10,\n",
    "        \"Combined\",\n",
    "        ha=\"right\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=base_fontsize * 1,\n",
    "    )\n",
    "\n",
    "    # Add labels\n",
    "    axs[1].set_xlabel(\n",
    "        \"Model frequency (%)\",\n",
    "        fontweight=\"bold\",\n",
    "        labelpad=10,\n",
    "        fontsize=base_fontsize * 1.2,\n",
    "    )\n",
    "    axs[1].set_ylabel(\n",
    "        # \"Climatic conditions before 2$^{\\\\text{nd}}$ visit\",\n",
    "        \"Short-term climatic condition\\npromoting mortality\",\n",
    "        labelpad=10,\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=base_fontsize * 1.2,\n",
    "    )\n",
    "\n",
    "    # Fix y-ticks\n",
    "    if ytick_labels is not None:\n",
    "        axs[1].set_yticklabels(ytick_labels, fontsize=base_fontsize * 1)\n",
    "\n",
    "    axs[1].set_yticks(range(len(patterns_merged[\"change_simple\"])))\n",
    "    axs[1].tick_params(axis=\"y\", which=\"both\", left=False)\n",
    "\n",
    "    # Fix axis limits\n",
    "    axs[1].set_xlim(0, 100)\n",
    "    axs[1].set_ylim(10.4, -0.4)\n",
    "\n",
    "    # Remove top and right axis\n",
    "    axs[1].spines[\"top\"].set_visible(False)\n",
    "    axs[1].spines[\"right\"].set_visible(False)\n",
    "\n",
    "    # Add letters\n",
    "    letters = [\"A\", \"B\"]\n",
    "    for i, ax in enumerate(axs):\n",
    "        ax.text(\n",
    "            -0.5,\n",
    "            0.99,\n",
    "            letters[i],\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=base_fontsize * 1.3,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "    # Fix layout\n",
    "    # Fix x-tick size\n",
    "    axs[0].tick_params(axis=\"x\", which=\"both\", labelsize=base_fontsize * 0.8)\n",
    "    axs[1].tick_params(axis=\"x\", which=\"both\", labelsize=base_fontsize * 0.8)\n",
    "    plt.tight_layout(w_pad=2, h_pad=1)\n",
    "\n",
    "    if filepath is not None:\n",
    "        plt.savefig(filepath, dpi=600, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def get_ns_per_pattern(df_in, pattern):\n",
    "    if pattern == \"warmer\" or pattern == \"cooler\":\n",
    "        var_all = \"change_temp_all\"\n",
    "        var_sign = \"change_temp\"\n",
    "    elif pattern == \"wetter\" or pattern == \"drier\":\n",
    "        var_all = \"change_spei_all\"\n",
    "        var_sign = \"change_spei\"\n",
    "    else:\n",
    "        var_all = \"change_both_all\"\n",
    "        var_sign = \"change_both_sign\"\n",
    "\n",
    "    # Remove NAs in the pattern column to avoid confusion with \"ns\" as relating to variable was not contained in the model and \"ns\" as relating to no significant pvalue\n",
    "    df_in = df_in.dropna(subset=[var_all])\n",
    "\n",
    "    # Get NA percentage\n",
    "    df_in = df_in.query(f\"{var_all} == '{pattern}'\")[var_sign].value_counts(\n",
    "        normalize=True\n",
    "    )[\"ns\"]\n",
    "\n",
    "    # Return\n",
    "    return df_in\n",
    "\n",
    "\n",
    "def ax_performance(ax, roc_or_auc, all_or_top9):\n",
    "\n",
    "    if roc_or_auc == \"roc\":\n",
    "        metric = \"ROC AUC\"\n",
    "        file_name = \"roc_auc\"\n",
    "    elif roc_or_auc == \"pr\":\n",
    "        metric = \"PR AUC\"\n",
    "        file_name = \"pr_auc\"\n",
    "    else:\n",
    "        raise ValueError(\"roc_or_auc must be 'roc' or 'pr'\")\n",
    "\n",
    "    df_comp_perf = []\n",
    "\n",
    "    for i, row in i_success.iterrows():\n",
    "\n",
    "        # Check if roc auc files are there\n",
    "        path_rf = (\n",
    "            f\"{path_prefix}/{row.model}/{row.species}/rf_performance/{file_name}.csv\"\n",
    "        )\n",
    "        path_glmm = (\n",
    "            f\"{path_prefix}/{row.model}/{row.species}/{path_suffix}/{file_name}.csv\"\n",
    "        )\n",
    "\n",
    "        if not os.path.isfile(path_glmm):\n",
    "            print(f\"GLMM file missing for {row.species} - {row.model}\")\n",
    "            continue\n",
    "        if not os.path.isfile(path_rf):\n",
    "            raise ValueError(f\"RF file missing: {path_rf}\")\n",
    "\n",
    "        # Attach files\n",
    "        irf = pd.read_csv(path_rf)\n",
    "        irf[\"species\"] = row.species\n",
    "        irf[\"model\"] = \"rf\"\n",
    "        irf[\"run\"] = row.model\n",
    "\n",
    "        iglmm = pd.read_csv(path_glmm)\n",
    "        iglmm[\"species\"] = row.species\n",
    "        iglmm[\"model\"] = \"glmm\"\n",
    "        iglmm[\"run\"] = row.model\n",
    "\n",
    "        df_comp_perf.append(irf)\n",
    "        df_comp_perf.append(iglmm)\n",
    "        display(path_glmm)\n",
    "\n",
    "    # Get data\n",
    "    df_plot = pd.concat(df_comp_perf)\n",
    "\n",
    "    if all_or_top9 == \"top9\":\n",
    "        df_plot = df_plot[df_plot[\"species\"].isin(top9)]\n",
    "\n",
    "    if roc_or_auc == \"roc\":\n",
    "        df_plot = df_plot[df_plot[\"test_mean\"] > roc_threshold]\n",
    "\n",
    "    # Get mean and std for each model\n",
    "    metric_table = df_plot.groupby([\"model\"]).agg(\n",
    "        {\"test_mean\": \"mean\", \"test_sd\": \"mean\"}\n",
    "    )\n",
    "    metric_rf = metric_table.loc[\"rf\"]\n",
    "    metric_rf = f\"RF: {metric_rf.test_mean:.2f} Â± {metric_rf.test_sd:.2f}\"\n",
    "    metric_glmm = metric_table.loc[\"glmm\"]\n",
    "    metric_glmm = f\"GLMM: {metric_glmm.test_mean:.2f} Â± {metric_glmm.test_sd:.2f}\"\n",
    "\n",
    "    # Replace model names with metrics\n",
    "    df_plot[\"model\"] = df_plot[\"model\"].replace({\"rf\": metric_rf, \"glmm\": metric_glmm})\n",
    "\n",
    "    sns.boxplot(\n",
    "        data=df_plot,\n",
    "        y=\"species\",\n",
    "        x=\"test_mean\",\n",
    "        hue=\"model\",  # Different colors for each model\n",
    "        palette=\"Set2\",  # Change color palette as desired\n",
    "        ax=ax,\n",
    "        # more space between species\n",
    "        width=0.7,\n",
    "    )\n",
    "\n",
    "    # Add titles and labels to the given ax\n",
    "    ax.set_xlabel(f\"{metric} on Test Set\", fontsize=10, fontweight=\"bold\")\n",
    "    if roc_or_auc == \"roc\":\n",
    "        ax.set_ylabel(\"Species\", fontsize=10, fontweight=\"bold\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.yaxis.tick_right()\n",
    "\n",
    "    # Rotate x-axis labels\n",
    "    ax.tick_params(axis=\"x\", labelrotation=0, labelsize=10)\n",
    "\n",
    "    # Show legend on the ax\n",
    "    pos = \"upper right\"  # if roc_or_auc == \"pr\" else \"upper left\"\n",
    "    ax.legend(title=None, loc=pos, fontsize=8, handlelength=0.8)\n",
    "\n",
    "    # Verbose\n",
    "    # print(\"Comparison of random forest and logistic glmm models:\")\n",
    "    # print(metric_rf)\n",
    "    # print(metric_glmm)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get todays analysis folder\n",
    "from datetime import datetime\n",
    "\n",
    "dir_today = f\"./model_analysis/{datetime.now().strftime('%Y-%m-%d')}/glmm_analysis\"\n",
    "os.makedirs(dir_today, exist_ok=True)\n",
    "dir_today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "all_or_top9 = \"all\"\n",
    "pval_threshold = 0.05  # For defining significant response\n",
    "roc_threshold = 0.6  # For defining successful models\n",
    "min_group_percentage = 0.6  # For aggregating response of same feature\n",
    "ns_for_insignificant = False  # Wording for insignificant p-values\n",
    "\n",
    "# Get paths\n",
    "path_prefix = \"./model_runs/all_runs\"\n",
    "if not os.path.exists(path_prefix):\n",
    "    path_prefix = \"/Volumes/SAMSUNG 1TB/all_runs\"\n",
    "    if not os.path.exists(path_prefix):\n",
    "        raise ValueError(f\"Path '{path_prefix}' does not exist. Please check the path.\")\n",
    "path_suffix = \"glmm/\"\n",
    "\n",
    "print(f\"GLMM path: '{path_prefix}/RUN/SPECIES/{path_suffix}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Species and Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_species = get_species_with_models(\"list\")\n",
    "\n",
    "top9 = final_species[:9]\n",
    "\n",
    "base_dir = path_prefix\n",
    "models_dir = os.listdir(base_dir)\n",
    "models_dir = [m for m in models_dir if not m.startswith(\".\")]\n",
    "models_dir = sorted(models_dir)\n",
    "\n",
    "# Merge species and model lists into one df\n",
    "models_species = list(itertools.product(models_dir, final_species))\n",
    "df_in = pd.DataFrame(models_species, columns=[\"model\", \"species\"])\n",
    "df_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ispecies = \"Abies grandis\"\n",
    "# imodel = \"run_51\"\n",
    "\n",
    "# glmm_run_per_species_and_model(\n",
    "#     ispecies,\n",
    "#     imodel,\n",
    "#     verbose=True,\n",
    "#     path_prefix=path_prefix,\n",
    "#     path_suffix=path_suffix,\n",
    "#     return_all=False,\n",
    "#     skip_if_exists=False,\n",
    "# )\n",
    "\n",
    "# ! Loop\n",
    "# for i, row in tqdm(df_in.reset_index(drop=True).iterrows(), total=len(df_in)):\n",
    "\n",
    "#     glmm_run_per_species_and_model(\n",
    "#         ispecies=row.species,\n",
    "#         imodel=row.model,\n",
    "#         path_prefix=path_prefix,\n",
    "#         path_suffix=path_suffix,\n",
    "#         return_all=False,\n",
    "#         verbose=False,\n",
    "#         skip_if_exists=True,\n",
    "#     )\n",
    "#     # clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from random_forest_utils import glmm_wrapper_loop\n",
    "\n",
    "# # Run glmm fitting in parallel:\n",
    "# out = run_mp(\n",
    "#     glmm_wrapper_loop,\n",
    "#     arg_list=split_df_into_list_of_group_or_ns(df_in, \"model\"),\n",
    "#     num_cores=10,\n",
    "#     progress_bar=True,\n",
    "#     verbose=False,\n",
    "#     path_prefix=path_prefix,\n",
    "#     path_suffix=path_suffix,\n",
    "#     return_all=False,\n",
    "#     skip_if_exists=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! osascript -e 'tell app \"System Events\" to shut down'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GLMM Runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which models have NO model created\n",
    "i_missing = []\n",
    "i_success = []\n",
    "for i, row in df_in.reset_index(drop=True).iterrows():\n",
    "    # Check for summary file because it is the last that should be saved per run\n",
    "    path_glmm = f\"{path_prefix}/{row.model}/{row.species}/{path_suffix}/summary.csv\"\n",
    "    if not os.path.isfile(path_glmm):\n",
    "        i_missing.append(row)\n",
    "    else:\n",
    "        i_success.append(row)\n",
    "\n",
    "if i_missing.__len__() > 0:\n",
    "    print(f\"Missing {i_missing.__len__()} models\")\n",
    "    i_missing = pd.concat(i_missing)\n",
    "    i_missing = pd.DataFrame(\n",
    "        {\"model\": i_missing.model.values, \"species\": i_missing.species.values}\n",
    "    )\n",
    "    print(\n",
    "        f\"Missing models: {i_missing.shape[0]} from {i_missing.model.nunique()} seeds and {i_missing.species.nunique()} species\"\n",
    "    )\n",
    "else:\n",
    "    print(\"All models are present\")\n",
    "\n",
    "i_success = pd.concat(i_success)\n",
    "i_success = pd.DataFrame(\n",
    "    {\"model\": i_success.model.values, \"species\": i_success.species.values}\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Successful models: {i_success.shape[0]} from {i_success.model.nunique()} seeds and {i_success.species.nunique()} species\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop over missing models to see which cause errors\n",
    "# verbose = True\n",
    "# for i, row in i_missing.reset_index(drop=True).iterrows():\n",
    "#     if verbose:\n",
    "#         print(f\"ðŸŸ¡ Species: {row.species}\\t | Model: {row.model}\")\n",
    "\n",
    "#     if \"61\" in row.model:\n",
    "#         print(\"Skipping: Alnus incana 61\")\n",
    "#         continue\n",
    "\n",
    "#     glmm_wrapper(\n",
    "#         ispecies=row.species,\n",
    "#         imodel=row.model,\n",
    "#         base_dir=path_prefix,\n",
    "#         return_all=False,\n",
    "#         verbose=False,\n",
    "#     )\n",
    "#     clear_output()\n",
    "#     if verbose:\n",
    "#         print(f\"ðŸŸ¡ Species: {row.species}\\t | Model: {row.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model directories\n",
    "df_available = glob.glob(f\"{path_prefix}/run_*/*/glmm/y_train_pred.csv\")\n",
    "df_available = pd.DataFrame(df_available, columns=[\"file\"])\n",
    "df_available[\"species\"] = df_available[\"file\"].str.split(\"/\").str[-3]\n",
    "df_available[\"model\"] = df_available[\"file\"].str.split(\"/\").str[-4]\n",
    "df_available[\"base_dir\"] = df_available[\"file\"].str.split(\"/run\").str[0] + \"/\"\n",
    "\n",
    "# Check for missing runs\n",
    "print(\" --- The following species do not have their 50 seed runs yet: ---\")\n",
    "print(f\" - Species found: {df_available['species'].nunique()}\")\n",
    "print(f\" - Seeds found: {df_available['model'].nunique()}\")\n",
    "\n",
    "# Reduce to missing runs\n",
    "df_todo = []\n",
    "for i, row in df_available.iterrows():\n",
    "    # Check if file exists\n",
    "    ifile = row.file.replace(\n",
    "        \"y_train_pred.csv\",\n",
    "        \"classification_metrics_fixed_threshold.csv\",\n",
    "    )\n",
    "    if not os.path.isfile(ifile):\n",
    "        df_todo.append(row)\n",
    "df_todo = pd.DataFrame(df_todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate model performance\n",
    "from random_forest_utils import calculate_glmm_performance\n",
    "\n",
    "if df_todo.shape[0] == 0:\n",
    "    print(\"âœ… All model have been run!\")\n",
    "else:\n",
    "    run_mp(\n",
    "        calculate_glmm_performance,\n",
    "        split_df_into_list_of_group_or_ns(df_todo, 10),\n",
    "        skip_if_csv_exists=False,\n",
    "        progress_bar=True,\n",
    "        num_cores=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_paths = glob.glob(f\"{path_prefix}/run_*/**/glmm/roc_auc.csv\")\n",
    "pr_paths = glob.glob(f\"{path_prefix}/run_*/**/glmm/pr_auc.csv\")\n",
    "clf_paths = glob.glob(\n",
    "    f\"{path_prefix}/run_*/**/glmm/classification_metrics_fixed_threshold.csv\"\n",
    ")\n",
    "\n",
    "df_mean = get_metrics_for_all_models_and_species(\n",
    "    \"mean\",\n",
    "    roc_threshold,\n",
    "    roc_paths,\n",
    "    pr_paths,\n",
    "    clf_paths,\n",
    ")\n",
    "\n",
    "df_sd = get_metrics_for_all_models_and_species(\n",
    "    \"sd\",\n",
    "    roc_threshold,\n",
    "    roc_paths,\n",
    "    pr_paths,\n",
    "    clf_paths,\n",
    ")\n",
    "\n",
    "df_mean.to_csv(f\"{dir_today}/glmm_model_performance_summary.csv\", index=False)\n",
    "df_sd.to_csv(f\"{dir_today}/glmm_model_performance_summary_std.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# ! Comparing performances of final models across different analyses\n",
    "# Load and compare final model performances\n",
    "files = [\n",
    "    sorted(\n",
    "        glob.glob(\n",
    "            \"./model_analysis/*/pattern_analysis/by_mk/roc_0.6-min_group_share_0.6/tables/model_performance_summary.csv\"\n",
    "        )\n",
    "    )[-1],\n",
    "    f\"{dir_today}/glmm_model_performance_summary.csv\",\n",
    "]\n",
    "analysis_type = [\"RF\", \"GLMM\"]\n",
    "\n",
    "files = pd.DataFrame(\n",
    "    {\n",
    "        \"file\": files,\n",
    "        \"analysis_type\": analysis_type,\n",
    "    }\n",
    ")\n",
    "\n",
    "df = []\n",
    "for i, row in files.iterrows():\n",
    "    tmp = pd.read_csv(row[\"file\"])\n",
    "    tmp = tmp.query(\"Species in ['Mean', 'SD']\")\n",
    "    tmp[\"analysis_type\"] = row[\"analysis_type\"]\n",
    "    tmp = tmp.rename(\n",
    "        columns={\n",
    "            \"Train Roc Auc\": \"Train ROC-AUC\",\n",
    "            \"Test Roc Auc\": \"Test ROC-AUC\",\n",
    "            \"Train Pr Auc\": \"Train PR-AUC\",\n",
    "            \"Test Pr Auc\": \"Test PR-AUC\",\n",
    "        }\n",
    "    )\n",
    "    df.append(tmp)\n",
    "\n",
    "df = pd.concat(df, ignore_index=True)\n",
    "\n",
    "# Filter only 'Mean' rows\n",
    "df_mean = df[df[\"Species\"] == \"Mean\"]\n",
    "\n",
    "# Metrics and styles\n",
    "metrics = [\"ROC-AUC\", \"PR-AUC\", \"Precision\", \"Recall\", \"F1\"]\n",
    "linestyles = {\"Train\": \"--\", \"Test\": \"-\"}\n",
    "colors = {\n",
    "    \"ROC-AUC\": \"tab:blue\",\n",
    "    \"PR-AUC\": \"tab:orange\",\n",
    "    \"Precision\": \"tab:green\",\n",
    "    \"Recall\": \"tab:red\",\n",
    "    \"F1\": \"tab:purple\",\n",
    "}\n",
    "markers = {\n",
    "    \"ROC-AUC\": \"o\",\n",
    "    \"PR-AUC\": \"s\",\n",
    "    \"Precision\": \"D\",\n",
    "    \"Recall\": \"^\",\n",
    "    \"F1\": \"v\",\n",
    "}\n",
    "\n",
    "# Melt to long format\n",
    "train_cols = [f\"Train {m}\" for m in metrics]\n",
    "train_cols = [f\"Train {m}\" for m in metrics]\n",
    "test_cols = [f\"Test {m}\" for m in metrics]\n",
    "\n",
    "df_train = df_mean[[\"analysis_type\"] + train_cols].melt(\n",
    "    id_vars=\"analysis_type\", var_name=\"Metric\", value_name=\"Score\"\n",
    ")\n",
    "df_train[\"Set\"] = \"Train\"\n",
    "df_train[\"Metric\"] = df_train[\"Metric\"].str.replace(\"Train \", \"\")\n",
    "\n",
    "df_test = df_mean[[\"analysis_type\"] + test_cols].melt(\n",
    "    id_vars=\"analysis_type\", var_name=\"Metric\", value_name=\"Score\"\n",
    ")\n",
    "df_test[\"Set\"] = \"Test\"\n",
    "df_test[\"Metric\"] = df_test[\"Metric\"].str.replace(\"Test \", \"\")\n",
    "\n",
    "df_long = pd.concat([df_train, df_test])\n",
    "\n",
    "# Melt SD data\n",
    "df_sd = df[df[\"Species\"] == \"SD\"]\n",
    "\n",
    "df_train_sd = df_sd[[\"analysis_type\"] + train_cols].melt(\n",
    "    id_vars=\"analysis_type\", var_name=\"Metric\", value_name=\"SD\"\n",
    ")\n",
    "df_train_sd[\"Set\"] = \"Train\"\n",
    "df_train_sd[\"Metric\"] = df_train_sd[\"Metric\"].str.replace(\"Train \", \"\")\n",
    "\n",
    "df_test_sd = df_sd[[\"analysis_type\"] + test_cols].melt(\n",
    "    id_vars=\"analysis_type\", var_name=\"Metric\", value_name=\"SD\"\n",
    ")\n",
    "df_test_sd[\"Set\"] = \"Test\"\n",
    "df_test_sd[\"Metric\"] = df_test_sd[\"Metric\"].str.replace(\"Test \", \"\")\n",
    "\n",
    "df_sd_long = pd.concat([df_train_sd, df_test_sd])\n",
    "\n",
    "# Merge SDs with main data\n",
    "df_long = pd.merge(\n",
    "    df_long, df_sd_long, on=[\"analysis_type\", \"Metric\", \"Set\"], how=\"left\"\n",
    ")\n",
    "\n",
    "# Plot with error bars\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "for metric in metrics:\n",
    "    for set_type in [\"Train\", \"Test\"]:\n",
    "        subset = df_long[(df_long[\"Metric\"] == metric) & (df_long[\"Set\"] == set_type)]\n",
    "        ax.plot(\n",
    "            subset[\"analysis_type\"],\n",
    "            subset[\"Score\"],\n",
    "            color=colors[metric],\n",
    "            linestyle=linestyles[set_type],\n",
    "            marker=markers[metric],\n",
    "            label=f\"{metric} ({set_type})\",  # Not used for legend directly\n",
    "            markersize=8,\n",
    "        )\n",
    "        # # With Error Bars\n",
    "        # ax.errorbar(\n",
    "        #     subset[\"analysis_type\"],\n",
    "        #     subset[\"Score\"],\n",
    "        #     yerr=subset[\"SD\"],\n",
    "        #     color=colors[metric],\n",
    "        #     linestyle=linestyles[set_type],\n",
    "        #     marker=markers[metric],\n",
    "        #     markersize=8,\n",
    "        #     capsize=4,\n",
    "        # )\n",
    "\n",
    "# Labels and style\n",
    "ax.set_title(\"Train vs Test Performance between RF and GLMM Models\")\n",
    "ax.set_xlabel(\"Analysis Type\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Custom legend\n",
    "metric_handles = [\n",
    "    Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        color=colors[m],\n",
    "        marker=markers[m],\n",
    "        linestyle=\"\",\n",
    "        markersize=8,\n",
    "        label=m,\n",
    "    )\n",
    "    for m in metrics\n",
    "]\n",
    "\n",
    "set_handles = [\n",
    "    Line2D([0], [0], color=\"gray\", linestyle=ls, lw=2, label=st)\n",
    "    for st, ls in linestyles.items()\n",
    "]\n",
    "\n",
    "ax.legend(\n",
    "    handles=metric_handles + set_handles,\n",
    "    title=\"\",\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1.01, 0.5),\n",
    "    frameon=False,\n",
    "    borderaxespad=0,\n",
    ")\n",
    "\n",
    "plt.savefig(\n",
    "    f\"{dir_today}/glmm_rf_model_performance_comparison.png\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare RF and GLMM performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create figure\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(10, 10))\n",
    "# axs = axs.flatten()\n",
    "# ax_performance(axs[0], \"roc\", \"all\")\n",
    "# ax_performance(axs[1], \"pr\", \"all\")\n",
    "# fig.tight_layout()\n",
    "# save_path = f\"{dir_today}/performance_comparison-all_species.png\"\n",
    "# fig.savefig(save_path, dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create figure\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "# axs = axs.flatten()\n",
    "# ax_performance(axs[0], \"roc\", \"top9\")\n",
    "# ax_performance(axs[1], \"pr\", \"top9\")\n",
    "# fig.tight_layout()\n",
    "# # save_path = f\"{dir_today}/performance_comparison-top9_species.png\"\n",
    "# # fig.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable importance comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and concat all results\n",
    "\n",
    "df_all = []\n",
    "for ispecies in final_species:\n",
    "    for imodel in models_dir:\n",
    "\n",
    "        path = f\"{path_prefix}/{imodel}/{ispecies}/{path_suffix}/summary.csv\"\n",
    "\n",
    "        # Load if file exists\n",
    "        if os.path.isfile(path):\n",
    "            idf = pd.read_csv(\n",
    "                path,\n",
    "                index_col=0,\n",
    "            )[[\"Estimate\", \"P-val\", \"2.5_ci\", \"97.5_ci\", \"SE\"]]\n",
    "\n",
    "            # Generalize columns names based on category\n",
    "            idf[\"dataset\"] = idf.index.map(get_category_from_var_wrapper)\n",
    "            idf = idf.reset_index().rename({\"index\": \"variable\"}, axis=1)\n",
    "\n",
    "            # Add info\n",
    "            idf[\"species\"] = ispecies\n",
    "            idf[\"model\"] = imodel\n",
    "            idf = move_vars_to_front(idf, [\"species\", \"model\", \"dataset\", \"variable\"])\n",
    "            df_all.append(idf)\n",
    "        else:\n",
    "            pass\n",
    "            print(f\"Missing: {ispecies} - {imodel}\")\n",
    "\n",
    "\n",
    "# Load data\n",
    "df_vimp = pd.concat(df_all)\n",
    "df_vimp = df_vimp[[\"species\", \"model\", \"dataset\", \"Estimate\"]]\n",
    "\n",
    "# Take estimate as importance proxy by taking the absolute value\n",
    "df_vimp[\"Estimate\"] = df_vimp[\"Estimate\"].abs() * 100\n",
    "\n",
    "# Take the mean per model-species-dataset combination (e.g. there are two temperature variables when linear and quad. are included)\n",
    "df_vimp = df_vimp.groupby([\"species\", \"model\", \"dataset\"]).mean().reset_index()\n",
    "\n",
    "# # Make wide df_vimp\n",
    "df_vimp = df_vimp.pivot(\n",
    "    index=[\"species\", \"model\"], columns=\"dataset\", values=\"Estimate\"\n",
    ").reset_index()\n",
    "\n",
    "# Drop intercept columns\n",
    "df_vimp = df_vimp.drop(\"Intercept\", axis=1)\n",
    "\n",
    "# For each row, divide the estimate by the sum of the estimates for that row\n",
    "df_vimp.iloc[:, 2:] = (\n",
    "    df_vimp.iloc[:, 2:].div(df_vimp.iloc[:, 2:].sum(axis=1), axis=0) * 100\n",
    ")\n",
    "\n",
    "# Display\n",
    "df_vimp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax_dataset_boxplot(\n",
    "    ax,\n",
    "    df_vimp,\n",
    "    df_vimp.columns[2:].tolist(),\n",
    "    base_fontsize=11,\n",
    "    pos_spei=4,\n",
    "    pos_temp=5,\n",
    "    all_or_top9=\"top9\",\n",
    ")\n",
    "ax.set_xlim(0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate climate effect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At model-level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speitemp_list = []\n",
    "\n",
    "for i, row in i_success.iterrows():\n",
    "\n",
    "    # Check if roc auc files are there\n",
    "    path_glmm = f\"{path_prefix}/{row.model}/{row.species}/{path_suffix}/summary.csv\"\n",
    "    path_perf = f\"{path_prefix}/{row.model}/{row.species}/{path_suffix}/roc_auc.csv\"\n",
    "\n",
    "    if not os.path.isfile(path_glmm) or not os.path.isfile(path_perf):\n",
    "        print(f\" - ðŸš¨ GLMM files incomplete for {row.species} - {row.model}\")\n",
    "        continue\n",
    "\n",
    "    # Load data\n",
    "    iper = pd.read_csv(path_perf)\n",
    "    isry = pd.read_csv(path_glmm, index_col=0)\n",
    "    var_spei = glmm_get_spei_var(isry.index)\n",
    "    var_temp = glmm_get_temp_var(isry.index)\n",
    "\n",
    "    if var_spei is None:\n",
    "        esti_spei = None\n",
    "        sign_spei = None\n",
    "        dire_spei = None\n",
    "        pval_spei = None\n",
    "        change_spei = None\n",
    "    else:\n",
    "        esti_spei = isry.loc[[var_spei]][\"Estimate\"].values[0]\n",
    "        sign_spei = isry.loc[[var_spei]][\"Sig\"].values[0]\n",
    "        dire_spei = np.sign(isry.loc[[var_spei]][\"Estimate\"].values[0])\n",
    "        pval_spei = isry.loc[[var_spei]][\"P-val\"].values[0]\n",
    "\n",
    "        if pval_spei < pval_threshold:\n",
    "            if dire_spei > 0:\n",
    "                change_spei = \"wetter\"\n",
    "            else:\n",
    "                change_spei = \"drier\"\n",
    "        else:\n",
    "            change_spei = \"ns\"\n",
    "\n",
    "    if var_temp is None:\n",
    "        esti_temp = None\n",
    "        sign_temp = None\n",
    "        dire_temp = None\n",
    "        pval_temp = None\n",
    "        change_temp = None\n",
    "    else:\n",
    "        esti_temp = isry.loc[[var_temp]][\"Estimate\"].values[0]\n",
    "        sign_temp = isry.loc[[var_temp]][\"Sig\"].values[0]\n",
    "        dire_temp = np.sign(isry.loc[[var_temp]][\"Estimate\"].values[0])\n",
    "        pval_temp = isry.loc[[var_temp]][\"P-val\"].values[0]\n",
    "\n",
    "        if pval_temp < pval_threshold:\n",
    "            if dire_temp > 0:\n",
    "                change_temp = \"warmer\"\n",
    "            else:\n",
    "                change_temp = \"cooler\"\n",
    "        else:\n",
    "            change_temp = \"ns\"\n",
    "\n",
    "    # Attach temp and spei information\n",
    "    df_speitemp_list.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"species\": row.species,\n",
    "                \"run\": row.model.split(\" -\")[0].split(\"_\")[1],\n",
    "                \"spei\": var_spei,\n",
    "                \"sign_spei\": sign_spei,\n",
    "                \"dire_spei\": dire_spei,\n",
    "                \"pval_spei\": pval_spei,\n",
    "                \"change_spei\": change_spei,\n",
    "                \"temp\": var_temp,\n",
    "                \"sign_temp\": sign_temp,\n",
    "                \"dire_temp\": dire_temp,\n",
    "                \"pval_temp\": pval_temp,\n",
    "                \"change_temp\": change_temp,\n",
    "                \"test_roc_auc\": iper[\"test_mean\"].values[0],\n",
    "            },\n",
    "            index=[0],\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Get dictionary\n",
    "dict_spei = {\n",
    "    +1: \"drier\",\n",
    "    -1: \"wetter\",\n",
    "}\n",
    "\n",
    "dict_temp = {\n",
    "    +1: \"warmer\",\n",
    "    -1: \"cooler\",\n",
    "}\n",
    "\n",
    "dict_ns = {\n",
    "    \"ns_ns\": \"ns\",\n",
    "    \"ns_wetter\": \"ns\",\n",
    "    \"ns_drier\": \"ns\",\n",
    "    \"warmer_ns\": \"ns\",\n",
    "    \"cooler_ns\": \"ns\",\n",
    "    \"warmer_wetter\": \"warmer_wetter\",\n",
    "    \"warmer_drier\": \"warmer_drier\",\n",
    "    \"cooler_wetter\": \"cooler_wetter\",\n",
    "    \"cooler_drier\": \"cooler_drier\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlist data\n",
    "df_pattern_per_model = pd.concat(df_speitemp_list)\n",
    "df_pattern_per_model[\"change_spei_all\"] = df_pattern_per_model[\"dire_spei\"].map(\n",
    "    dict_spei\n",
    ")\n",
    "df_pattern_per_model[\"change_temp_all\"] = df_pattern_per_model[\"dire_temp\"].map(\n",
    "    dict_temp\n",
    ")\n",
    "df_pattern_per_model[\"change_both_all\"] = (\n",
    "    df_pattern_per_model[\"change_temp_all\"]\n",
    "    + \"_\"\n",
    "    + df_pattern_per_model[\"change_spei_all\"]\n",
    ")\n",
    "df_pattern_per_model[\"change_both_sign\"] = (\n",
    "    df_pattern_per_model[\"change_temp\"] + \"_\" + df_pattern_per_model[\"change_spei\"]\n",
    ")\n",
    "df_pattern_per_model[\"change_both_sign\"] = df_pattern_per_model[\"change_both_sign\"].map(\n",
    "    dict_ns\n",
    ")\n",
    "\n",
    "\n",
    "for all_or_top9 in [\"all\", \"top9\"]:\n",
    "    if all_or_top9 == \"top9\":\n",
    "        text = \"Top 9 species\"\n",
    "        df_tmp = df_pattern_per_model.query(\"species in @top9\").copy()\n",
    "    else:\n",
    "        df_tmp = df_pattern_per_model.copy()\n",
    "        text = \"All species\"\n",
    "\n",
    "    display(f\"----- ðŸš¨ {text} ------\")\n",
    "\n",
    "    print(\"--- Change patterns all ---\")\n",
    "    display(df_tmp.change_temp_all.value_counts(normalize=True).sort_values().round(2))\n",
    "    display(df_tmp.change_spei_all.value_counts(normalize=True).sort_values().round(2))\n",
    "    display(df_tmp.change_both_all.value_counts(normalize=True).sort_values().round(2))\n",
    "\n",
    "    print(f\"--- Change patterns significant at p = {pval_threshold}---\")\n",
    "    display(df_tmp.change_temp.value_counts(normalize=True).sort_values().round(2))\n",
    "    display(df_tmp.change_spei.value_counts(normalize=True).sort_values().round(2))\n",
    "    print(f\"- Both with ns\")\n",
    "    display(df_tmp.change_both_sign.value_counts(normalize=True).sort_values().round(2))\n",
    "    print(f\"- Both without ns\")\n",
    "    display(\n",
    "        df_tmp.query(\"change_both_sign != 'ns'\")\n",
    "        .change_both_sign.value_counts(normalize=True)\n",
    "        .sort_values()\n",
    "        .round(2)\n",
    "    )\n",
    "\n",
    "    # fx(df_tmp, \"wetter\")\n",
    "    # fx(df_tmp, \"drier\")\n",
    "    # fx(df_tmp, \"warmer\")\n",
    "    # fx(df_tmp, \"cooler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_nonsignificant = True\n",
    "\n",
    "if keep_nonsignificant:\n",
    "    tmp_suffix = \"_all\"\n",
    "else:\n",
    "    tmp_suffix = \"\"\n",
    "\n",
    "df_res_lm = (\n",
    "    df_pattern_per_model.sort_values(\"species\")\n",
    "    .rename(\n",
    "        columns={\n",
    "            f\"change_spei{tmp_suffix}\": \"response_spei\",\n",
    "            f\"change_temp{tmp_suffix}\": \"response_temp\",\n",
    "        }\n",
    "    )\n",
    "    .query(\"test_roc_auc > @roc_threshold\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# display(df_res_lm)\n",
    "\n",
    "# Group by species and spei/temp variables\n",
    "df_res_lm_group = (\n",
    "    df_res_lm.dropna(subset=[\"response_spei\", \"response_temp\"])\n",
    "    # .query(\"dire_spei == 0 or dire_temp == 0\")\n",
    "    .groupby([\"species\", \"spei\", \"temp\"])\n",
    ")\n",
    "\n",
    "df_list = []\n",
    "\n",
    "i = 0\n",
    "ispecies = \"\"\n",
    "\n",
    "for group in df_res_lm_group.groups:\n",
    "\n",
    "    # Increment group counter\n",
    "    if ispecies == group[0]:\n",
    "        group_counter = group_counter + 1\n",
    "    else:\n",
    "        group_counter = 1\n",
    "        ispecies = group[0]\n",
    "\n",
    "    # Get group\n",
    "    df_group = df_res_lm_group.get_group(group)\n",
    "    # Get group size\n",
    "    group_size = df_group.shape[0]\n",
    "    # Get pattern percentages\n",
    "    spei_pattern, spei_value = get_var_and_val(df_group, \"spei\", min_group_percentage)\n",
    "    temp_pattern, temp_value = get_var_and_val(df_group, \"temp\", min_group_percentage)\n",
    "\n",
    "    idf = pd.DataFrame(\n",
    "        {\n",
    "            \"species\": group[0],\n",
    "            \"spei\": group[1],\n",
    "            \"temp\": group[2],\n",
    "            \"group\": group_counter,\n",
    "            \"group_size\": group_size,\n",
    "            \"response_spei\": spei_pattern,\n",
    "            \"response_temp\": temp_pattern,\n",
    "            \"perc_spei\": spei_value,\n",
    "            \"perc_temp\": temp_value,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    df_list.append(idf)\n",
    "    # display(idf)\n",
    "    # display(df_group)\n",
    "\n",
    "\n",
    "# pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_patterns = pd.concat(df_list)\n",
    "df_patterns[\"change\"] = (\n",
    "    df_patterns[\"response_temp\"] + \"_\" + df_patterns[\"response_spei\"]\n",
    ")\n",
    "\n",
    "# If ns is in change, then it is ns\n",
    "df_patterns[\"change\"] = df_patterns[\"change\"].apply(lambda x: \"ns\" if \"ns\" in x else x)\n",
    "df_patterns.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all species\n",
    "pattern_both = plot_pattern_dist(df_patterns, \"change\")\n",
    "pattern_spei = plot_pattern_dist(df_patterns, \"response_spei\")\n",
    "pattern_temp = plot_pattern_dist(df_patterns, \"response_temp\")\n",
    "\n",
    "patterns_merged_allspecies = pd.concat(\n",
    "    [\n",
    "        pattern_temp.replace({\"ns\": \"ns (temp)\"}),\n",
    "        pattern_spei.replace({\"ns\": \"ns (spei)\"}),\n",
    "        pattern_both,\n",
    "    ],\n",
    "    axis=0,\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# For all species\n",
    "pattern_both = plot_pattern_dist(df_patterns.query(\"species in @top9\"), \"change\")\n",
    "pattern_spei = plot_pattern_dist(df_patterns.query(\"species in @top9\"), \"response_spei\")\n",
    "pattern_temp = plot_pattern_dist(df_patterns.query(\"species in @top9\"), \"response_temp\")\n",
    "\n",
    "patterns_merged_top9 = pd.concat(\n",
    "    [\n",
    "        pattern_temp.replace({\"ns\": \"ns (temp)\"}),\n",
    "        pattern_spei.replace({\"ns\": \"ns (spei)\"}),\n",
    "        pattern_both,\n",
    "    ],\n",
    "    axis=0,\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_with_grouped_response = pd.merge(\n",
    "    df_res_lm[[\"species\", \"spei\", \"temp\", \"run\", \"pval_spei\", \"pval_temp\"]],\n",
    "    df_patterns[\n",
    "        [\n",
    "            \"species\",\n",
    "            \"spei\",\n",
    "            \"temp\",\n",
    "            \"group_size\",\n",
    "            \"response_temp\",\n",
    "            \"response_spei\",\n",
    "            \"change\",\n",
    "        ]\n",
    "    ],\n",
    "    how=\"left\",\n",
    "    on=[\"species\", \"spei\", \"temp\"],\n",
    ")\n",
    "\n",
    "# Keep original pval for checking later on\n",
    "df_models_with_grouped_response[\"pval_spei_org\"] = (\n",
    "    df_models_with_grouped_response[\"pval_spei\"].copy().round(3)\n",
    ")\n",
    "df_models_with_grouped_response[\"pval_temp_org\"] = (\n",
    "    df_models_with_grouped_response[\"pval_temp\"].copy().round(3)\n",
    ")\n",
    "\n",
    "# Attach pval for both spei and temp\n",
    "df_models_with_grouped_response[\"pval_spei\"] = df_models_with_grouped_response[\n",
    "    \"pval_spei\"\n",
    "].fillna(1)\n",
    "df_models_with_grouped_response[\"pval_spei\"] = (\n",
    "    df_models_with_grouped_response[\"pval_spei\"] < pval_threshold\n",
    ")\n",
    "df_models_with_grouped_response[\"pval_temp\"] = df_models_with_grouped_response[\n",
    "    \"pval_temp\"\n",
    "].fillna(1)\n",
    "\n",
    "df_models_with_grouped_response[\"pval_temp\"] = (\n",
    "    df_models_with_grouped_response[\"pval_temp\"] < pval_threshold\n",
    ")\n",
    "\n",
    "df_models_with_grouped_response[\"pval_both\"] = (\n",
    "    df_models_with_grouped_response[\"pval_spei\"] == True\n",
    ") & (df_models_with_grouped_response[\"pval_temp\"] == True)\n",
    "\n",
    "# Attach spei_temp pair\n",
    "df_models_with_grouped_response[\"spei_temp\"] = (\n",
    "    df_models_with_grouped_response[\"spei\"]\n",
    "    + \"-\"\n",
    "    + df_models_with_grouped_response[\"temp\"]\n",
    ")\n",
    "\n",
    "df_models_with_grouped_response.sort_values(\n",
    "    [\"species\", \"group_size\", \"spei_temp\"], ascending=[True, False, True]\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ! Assess significance of features\n",
    "list_all = []\n",
    "list_top9 = []\n",
    "\n",
    "for pattern in [\n",
    "    \"warmer\",\n",
    "    \"cooler\",\n",
    "    \"wetter\",\n",
    "    \"drier\",\n",
    "    \"warmer_wetter\",\n",
    "    \"warmer_drier\",\n",
    "    \"cooler_wetter\",\n",
    "    \"cooler_drier\",\n",
    "    \"ns (temp)\",\n",
    "    \"ns (spei)\",\n",
    "    \"ns\",\n",
    "]:\n",
    "    if pattern == \"warmer\" or pattern == \"cooler\" or pattern == \"ns (temp)\":\n",
    "        var_all = \"response_temp\"\n",
    "        var_sign = \"pval_temp\"\n",
    "        search_pattern = pattern\n",
    "    elif pattern == \"wetter\" or pattern == \"drier\" or pattern == \"ns (spei)\":\n",
    "        var_all = \"response_spei\"\n",
    "        var_sign = \"pval_spei\"\n",
    "        search_pattern = pattern\n",
    "    else:\n",
    "        var_all = \"change\"\n",
    "        var_sign = \"pval_both\"\n",
    "        search_pattern = pattern\n",
    "\n",
    "    if \"ns\" in pattern:\n",
    "        search_pattern = \"ns\"\n",
    "\n",
    "    # All\n",
    "    xxx = df_models_with_grouped_response.query(f\"{var_all} == '{search_pattern}'\")\n",
    "    xxx = xxx[var_sign].value_counts(normalize=True).sort_index()\n",
    "    xxx[\"response\"] = var_all\n",
    "    xxx[\"pattern\"] = pattern\n",
    "    xxx = xxx.to_frame().T\n",
    "    list_all.append(xxx)\n",
    "\n",
    "    # Top9\n",
    "    xxx = df_models_with_grouped_response.query(\n",
    "        f\"{var_all} == '{search_pattern}' and species in @top9\"\n",
    "    )\n",
    "    xxx = xxx[var_sign].value_counts(normalize=True).sort_index()\n",
    "    xxx[\"response\"] = var_all\n",
    "    xxx[\"pattern\"] = pattern\n",
    "    xxx = xxx.to_frame().T\n",
    "    list_top9.append(xxx)\n",
    "\n",
    "\n",
    "df_significance_all_species = pd.concat(list_all).reset_index(drop=True)\n",
    "df_significance_all_species = df_significance_all_species.drop(\n",
    "    columns=[\n",
    "        \"response\",\n",
    "        # \"pval_spei\",\n",
    "    ]\n",
    ").rename(columns={False: \"ns\", True: \"sig\"})\n",
    "\n",
    "df_significance_top9 = pd.concat(list_top9).reset_index(drop=True)\n",
    "df_significance_top9 = df_significance_top9.drop(\n",
    "    columns=[\n",
    "        \"response\",\n",
    "        # \"pval_spei\",\n",
    "    ]\n",
    ").rename(columns={False: \"ns\", True: \"sig\"})\n",
    "\n",
    "# Show\n",
    "display(df_significance_all_species)\n",
    "display(df_significance_top9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Get final df for plotting\n",
    "for all_or_top9 in [\"all\", \"top9\"]:\n",
    "    print(f\" --- {all_or_top9} ---\")\n",
    "\n",
    "    df_tmp = df_vimp.copy()\n",
    "    if all_or_top9 == \"top9\":\n",
    "        df_tmp = df_tmp[df_tmp[\"species\"].isin(top9)]\n",
    "\n",
    "    if all_or_top9 == \"all\":\n",
    "        df_plot = pd.merge(\n",
    "            patterns_merged_allspecies,\n",
    "            df_significance_all_species,\n",
    "            left_on=\"change_simple\",\n",
    "            right_on=\"pattern\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        left_ylim = 60\n",
    "        ytick_labels = [\n",
    "            \"Warmer\".title(),\n",
    "            \"Cooler\".title(),\n",
    "            \"Other\".title(),\n",
    "            \"Drier\".title(),\n",
    "            \"Wetter\".title(),\n",
    "            \"Other\".title(),\n",
    "            \"Warmer + Drier\".title(),\n",
    "            \"Warmer + Wetter\".title(),\n",
    "            \"Cooler + Drier\".title(),\n",
    "            \"Cooler + Wetter\".title(),\n",
    "            \"Other\".title(),\n",
    "        ]\n",
    "    else:\n",
    "        df_plot = pd.merge(\n",
    "            patterns_merged_top9,\n",
    "            df_significance_top9,\n",
    "            left_on=\"change_simple\",\n",
    "            right_on=\"pattern\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        left_ylim = 60\n",
    "\n",
    "    # Split group size into ns and sig\n",
    "    df_plot[\"perc_sign\"] = df_plot[\"group_size_rel\"] * (1 - df_plot[\"ns\"])\n",
    "    df_plot[\"perc_ns\"] = df_plot[\"group_size_rel\"] * df_plot[\"ns\"]\n",
    "\n",
    "    # Fix the perc_xxx columns where ns was NA. FIll with group_size_rel\n",
    "    df_plot[\"perc_sign\"] = df_plot[\"perc_sign\"].fillna(df_plot[\"group_size_rel\"])\n",
    "    df_plot[\"perc_ns\"] = df_plot[\"perc_ns\"].fillna(0)\n",
    "\n",
    "    # Switch ns for unclear\n",
    "    df_plot[\"change_simple\"] = df_plot[\"change_simple\"].replace(\n",
    "        {\"ns\": \"unclear\", \"ns (spei)\": \"unclear (spei)\", \"ns (temp)\": \"unclear (temp)\"}\n",
    "    )\n",
    "\n",
    "    # Show\n",
    "    display(\n",
    "        df_plot[\n",
    "            [\n",
    "                \"change_simple\",\n",
    "                \"group_size_rel\",\n",
    "                \"pattern\",\n",
    "                \"ns\",\n",
    "                \"sig\",\n",
    "                \"perc_sign\",\n",
    "                \"perc_ns\",\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # ! Make Plot\n",
    "    color_temp = \"#77422C\"\n",
    "    color_spei = \"#D1A289\"\n",
    "    color_rest = \"lightgrey\"\n",
    "    color_wd = sns.color_palette(\"Reds\", 3)[-1]\n",
    "    color_ww = sns.color_palette(\"Blues\", 3)[-1]\n",
    "    color_other = \"lightgrey\"\n",
    "\n",
    "    plot_bars_dataset_pattern(\n",
    "        df_plot,\n",
    "        df_tmp,\n",
    "        all_or_top9=all_or_top9,\n",
    "        color_temp=color_temp,\n",
    "        color_spei=color_spei,\n",
    "        color_rest=color_rest,\n",
    "        color_wd=color_wd,\n",
    "        color_ww=color_ww,\n",
    "        color_other=color_other,\n",
    "        filepath=f\"{dir_today}/{all_or_top9}.png\",\n",
    "        ytick_labels=ytick_labels,\n",
    "        left_ylim=left_ylim,\n",
    "    )\n",
    "\n",
    "    # ! Importance distribution\n",
    "    df_tmp = df_tmp.drop(columns=[\"species\", \"model\"]).mean()\n",
    "    imp_stand = (\n",
    "        df_tmp[\"Light Competition\"]\n",
    "        + df_tmp[\"Species Competition\"]\n",
    "        + df_tmp[\"Stand Structure\"]\n",
    "        + df_tmp[\"Tree Size\"]\n",
    "    ).round(0)\n",
    "\n",
    "    imp_climate = (df_tmp[\"Temperature\"] + df_tmp[\"SPEI\"]).round(2)\n",
    "    imp_soil = (df_tmp[\"Soil Fertility\"] + df_tmp[\"Soil Water Conditions\"]).round(0)\n",
    "    imp_ndvi = (df_tmp[\"NDVI\"]).round(0)\n",
    "\n",
    "    display(df_tmp.round(2).sort_values(ascending=False))\n",
    "    print(f\"Sum of Stand-describing variables: {imp_stand}\")\n",
    "    print(f\"Sum of Climate-describing variables: {imp_climate}\")\n",
    "    print(f\"Sum of Soil-describing variables: {imp_soil}\")\n",
    "    print(f\"Sum of NDVI variables: {imp_ndvi}\\n\\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# User input\n",
    "fig_top = f\"{dir_today}/top9.png\"\n",
    "fig_bot = f\"{dir_today}/all.png\"\n",
    "output_file = f\"{dir_today}/si_summary_importance.png\"\n",
    "\n",
    "# Panel label positions in figure coordinates\n",
    "label_letters = [\"A\", \"B\", \"C\", \"D\"]\n",
    "label_x_coords = [0.025, 0.515, 0.025, 0.515]\n",
    "label_y_coords = [0.865, 0.865, 0.445, 0.445]\n",
    "\n",
    "# Square figure size\n",
    "fig_size = 8  # inches\n",
    "fig = plt.figure(figsize=(fig_size, fig_size))\n",
    "gs = GridSpec(nrows=2, ncols=1, height_ratios=[1, 1], figure=fig)\n",
    "axs = [fig.add_subplot(gs[i, 0]) for i in range(2)]\n",
    "\n",
    "# Plot images\n",
    "for ax, img_path in zip(axs, [fig_top, fig_bot]):\n",
    "    img = mpimg.imread(img_path)\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Add labels using fixed (x, y) in figure coordinates\n",
    "for label, x, y in zip(label_letters, label_x_coords, label_y_coords):\n",
    "    fig.text(\n",
    "        x,\n",
    "        y,\n",
    "        label,\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "        ha=\"left\",\n",
    "        va=\"top\",\n",
    "        bbox=dict(facecolor=\"white\", edgecolor=\"none\", pad=2),\n",
    "    )\n",
    "\n",
    "# Save and show\n",
    "plt.tight_layout(h_pad=0)\n",
    "plt.savefig(output_file, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(f\"Figure saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
