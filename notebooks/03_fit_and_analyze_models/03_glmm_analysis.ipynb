{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLMM Verification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../../src\")\n",
    "from imports import *\n",
    "\n",
    "init_notebook()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fx(df, change):\n",
    "    if change in [\"warmer\", \"cooler\"]:\n",
    "        values = df.query(\"change_temp_all == @change\")[\"pval_temp\"]\n",
    "        mean = values.mean()\n",
    "    else:\n",
    "        values = df.query(\"change_spei_all == @change\")[\"pval_spei\"]\n",
    "        mean = values.mean()\n",
    "\n",
    "    # print(f\"Mean p-value for {change}: {mean:.2f}\")\n",
    "    ax, fig = plt.subplots(figsize=(3, 3))\n",
    "    sns.histplot(values, kde=True, bins=20)\n",
    "    # Add legend\n",
    "    plt.legend([f\"{change} mean: {mean:.2f}\"])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_var_and_val(df_tmp, response_var, var_pval_threshold=0.05, group_threshold=0.6):\n",
    "\n",
    "    pvar = f\"pval_{response_var}\"\n",
    "    # df_tmp = df_tmp[df_tmp[pvar] < var_pval_threshold]\n",
    "    # display(df_tmp)\n",
    "\n",
    "    df_tmp = (\n",
    "        df_tmp[f\"response_{response_var}\"]\n",
    "        .value_counts(normalize=True)\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    ipattern = df_tmp.index[0]\n",
    "    ivalue = df_tmp.values[0]\n",
    "    if ivalue < group_threshold:\n",
    "        ipattern = \"ns\"\n",
    "\n",
    "    return ipattern, ivalue\n",
    "\n",
    "\n",
    "def plot_pattern_dist(df_in, var_in, dir_patterns=None):\n",
    "    # Sum up runs per group\n",
    "    df_in = (\n",
    "        df_in.groupby(var_in).agg(group_size_rel=(\"group_size\", \"sum\")).reset_index()\n",
    "    )\n",
    "    # Take percentage and turn into int\n",
    "    df_in[\"group_size_rel\"] = (\n",
    "        df_in[\"group_size_rel\"] / df_in[\"group_size_rel\"].sum() * 100\n",
    "    )\n",
    "    df_in[\"group_size_rel\"] = df_in[\"group_size_rel\"].round(0)\n",
    "    df_in[\"group_size_rel\"] = df_in[\"group_size_rel\"].astype(int)\n",
    "    # Sort by percentage\n",
    "    df_in = df_in.sort_values(\"group_size_rel\", ascending=True)\n",
    "    # Add percentage to label\n",
    "    df_in[\"change_simple\"] = df_in[var_in]\n",
    "    df_in[var_in] = df_in[var_in] + \" (\" + df_in[\"group_size_rel\"].astype(str) + \"%)\"\n",
    "    # Plot it\n",
    "    df_in = df_in.sort_values(\"group_size_rel\", ascending=False).reset_index(drop=True)\n",
    "    # display(df_in)\n",
    "    return df_in\n",
    "    # df_in.plot(kind=\"barh\", x=var_in, y=\"group_size_rel\", color=\"grey\", legend=False)\n",
    "    # plt.xlabel(\"Share of all runs (%)\")\n",
    "    # plt.ylabel(\"\")\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig(f\"{dir_patterns}/change_counts_before_merging_unclear_{var_in}.png\")\n",
    "    # plt.show()\n",
    "    # plt.close()\n",
    "\n",
    "\n",
    "def plot_bars_dataset_pattern(\n",
    "    patterns_merged,\n",
    "    all_dfs,\n",
    "    all_or_top9=\"all\",\n",
    "    color_temp=\"#77422C\",\n",
    "    color_spei=\"#D1A289\",\n",
    "    color_rest=\"lightgrey\",\n",
    "    color_wd=\"#B2182B\",  # Original: \"#B2182B\"\n",
    "    color_ww=\"#2166AC\",  # Original: \"#2166AC\"\n",
    "    color_other=\"lightgrey\",\n",
    "    color_cd=\"lightgrey\",  # Original: \"#EF8A62\",\n",
    "    color_cw=\"lightgrey\",  # Original: \"#67A9CF\",\n",
    "    ytick_labels=None,\n",
    "    left_ylim=60,\n",
    "    base_fontsize=12,\n",
    "    filepath=None,\n",
    "):\n",
    "    # Plot\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 5))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Barplot for importance\n",
    "    if all_or_top9 == \"top9\":\n",
    "        pos_temp = 5\n",
    "        pos_spei = 6\n",
    "    elif all_or_top9 == \"all\":\n",
    "        pos_temp = 4\n",
    "        pos_spei = 5\n",
    "\n",
    "    ax_dataset_boxplot(\n",
    "        axs[0],\n",
    "        all_dfs,\n",
    "        all_dfs.columns[2:].tolist(),\n",
    "        base_fontsize,\n",
    "        pos_spei=pos_spei,\n",
    "        pos_temp=pos_temp,\n",
    "        color_spei=color_spei,\n",
    "        color_temp=color_temp,\n",
    "        color_rest=color_rest,\n",
    "        all_or_top9=all_or_top9,\n",
    "    )\n",
    "    axs[0].set_xlim(0, left_ylim)\n",
    "\n",
    "    # ax_dataset_boxplot(\n",
    "    #     axs[0],\n",
    "    #     all_dfs,\n",
    "    #     imps,\n",
    "    #     base_fontsize,\n",
    "    #     color_spei=color_spei,\n",
    "    #     color_temp=color_temp,\n",
    "    #     color_rest=color_rest,\n",
    "    #     all_or_top9=all_or_top9,\n",
    "    # )\n",
    "\n",
    "    # Barplot for patterns\n",
    "    sns.barplot(\n",
    "        data=patterns_merged,\n",
    "        x=\"group_size_rel\",\n",
    "        y=\"change_simple\",\n",
    "        hue=\"change_simple\",\n",
    "        palette=[\n",
    "            color_temp,\n",
    "            color_temp,\n",
    "            color_temp,\n",
    "            color_spei,\n",
    "            color_spei,\n",
    "            color_spei,\n",
    "            color_wd,\n",
    "            color_ww,\n",
    "            color_other,\n",
    "            color_cd,\n",
    "            color_cw,\n",
    "        ],\n",
    "        orient=\"h\",\n",
    "        height=0.5,\n",
    "        dodge=False,\n",
    "        edgecolor=\"black\",\n",
    "        # hue=\"response_spei\",\n",
    "        # palette=[\n",
    "        #     \"#B2182B\",\n",
    "        #     \"#2166AC\",\n",
    "        #     \"grey\",\n",
    "        # ],\n",
    "        ax=axs[1],\n",
    "    )\n",
    "\n",
    "    # Add values to end of bars\n",
    "    for i in range(len(patterns_merged)):\n",
    "        axs[1].text(\n",
    "            patterns_merged.loc[i, \"group_size_rel\"] + 1,\n",
    "            i + -0.1,\n",
    "            # f\"{patterns_merged.loc[i, 'group_size_rel']} %\",\n",
    "            f\"{patterns_merged.loc[i, 'group_size_rel']} % (sign: {patterns_merged.loc[i, 'perc_sign'].round(0).astype(int)}%)\",\n",
    "            va=\"center\",\n",
    "            fontsize=base_fontsize * 0.9,\n",
    "        )\n",
    "\n",
    "    # Add horizontal lines\n",
    "    axs[1].axhline(2.35, color=\"black\", linewidth=1)\n",
    "    axs[1].axhline(5.35, color=\"black\", linewidth=1)\n",
    "\n",
    "    # Add text\n",
    "    axs[1].text(\n",
    "        95,\n",
    "        2,\n",
    "        \"Temperature\\nanomaly\",\n",
    "        ha=\"right\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=base_fontsize * 1,\n",
    "    )\n",
    "    axs[1].text(\n",
    "        95,\n",
    "        5,\n",
    "        \"CWB anomaly\",\n",
    "        ha=\"right\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=base_fontsize * 1,\n",
    "    )\n",
    "    axs[1].text(\n",
    "        95,\n",
    "        10,\n",
    "        \"Combined\",\n",
    "        ha=\"right\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=base_fontsize * 1,\n",
    "    )\n",
    "\n",
    "    # Add labels\n",
    "    axs[1].set_xlabel(\n",
    "        \"Model frequency (%)\",\n",
    "        fontweight=\"bold\",\n",
    "        labelpad=10,\n",
    "        fontsize=base_fontsize * 1.2,\n",
    "    )\n",
    "    axs[1].set_ylabel(\n",
    "        # \"Climatic conditions before 2$^{\\\\text{nd}}$ visit\",\n",
    "        \"Short-term climatic condition\\npromoting mortality\",\n",
    "        labelpad=10,\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=base_fontsize * 1.2,\n",
    "    )\n",
    "\n",
    "    # Fix y-ticks\n",
    "    if ytick_labels is not None:\n",
    "        axs[1].set_yticklabels(ytick_labels, fontsize=base_fontsize * 1)\n",
    "\n",
    "    axs[1].set_yticks(range(len(patterns_merged[\"change_simple\"])))\n",
    "    axs[1].tick_params(axis=\"y\", which=\"both\", left=False)\n",
    "\n",
    "    # Rename y-ticks\n",
    "    # Todo: needs flexible fixing in case the order is not as assumed\n",
    "    # axs[1].set_yticklabels(\n",
    "    #     [\n",
    "    #         \"Warmer\".title(),\n",
    "    #         \"Cooler\".title(),\n",
    "    #         \"Non Sign.\".title(),\n",
    "    #         \"Drier\".title(),\n",
    "    #         \"Wetter\".title(),\n",
    "    #         \"Non Sign.\".title(),\n",
    "    #         \"Warmer + Drier\".title(),\n",
    "    #         \"Warmer + Wetter\".title(),\n",
    "    #         \"Non Sign.\".title(),\n",
    "    #         \"Cooler + Drier\".title(),\n",
    "    #         \"Cooler + Wetter\".title(),\n",
    "    #     ],\n",
    "    # )\n",
    "\n",
    "    # Fix axis limits\n",
    "    axs[1].set_xlim(0, 100)\n",
    "    axs[1].set_ylim(10.4, -0.4)\n",
    "\n",
    "    # Remove top and right axis\n",
    "    axs[1].spines[\"top\"].set_visible(False)\n",
    "    axs[1].spines[\"right\"].set_visible(False)\n",
    "\n",
    "    # Add letters\n",
    "    letters = [\"A\", \"B\"]\n",
    "    for i, ax in enumerate(axs):\n",
    "        ax.text(\n",
    "            -0.5,\n",
    "            0.99,\n",
    "            letters[i],\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=base_fontsize * 1.3,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "    # Fix layout\n",
    "    # Fix x-tick size\n",
    "    axs[0].tick_params(axis=\"x\", which=\"both\", labelsize=base_fontsize * 0.8)\n",
    "    axs[1].tick_params(axis=\"x\", which=\"both\", labelsize=base_fontsize * 0.8)\n",
    "    plt.tight_layout(w_pad=2, h_pad=1)\n",
    "\n",
    "    if filepath is not None:\n",
    "        plt.savefig(filepath, dpi=600, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def get_ns_per_pattern(df_in, pattern):\n",
    "    if pattern == \"warmer\" or pattern == \"cooler\":\n",
    "        var_all = \"change_temp_all\"\n",
    "        var_sign = \"change_temp\"\n",
    "    elif pattern == \"wetter\" or pattern == \"drier\":\n",
    "        var_all = \"change_spei_all\"\n",
    "        var_sign = \"change_spei\"\n",
    "    else:\n",
    "        var_all = \"change_both_all\"\n",
    "        var_sign = \"change_both_sign\"\n",
    "\n",
    "    # Remove NAs in the pattern column to avoid confusion with \"ns\" as relating to variable was not contained in the model and \"ns\" as relating to no significant pvalue\n",
    "    df_in = df_in.dropna(subset=[var_all])\n",
    "\n",
    "    # Get NA percentage\n",
    "    df_in = df_in.query(f\"{var_all} == '{pattern}'\")[var_sign].value_counts(\n",
    "        normalize=True\n",
    "    )[\"ns\"]\n",
    "\n",
    "    # Return\n",
    "    return df_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection\n",
    "add_spei_temp_interaction = False\n",
    "add_spei_temp_derivatives = False\n",
    "\n",
    "do_rfe = False\n",
    "rfe_with_interactions = False\n",
    "best_model_method = \"AIC\"\n",
    "\n",
    "# Model filter\n",
    "all_or_top9 = \"all\"\n",
    "roc_threshold = 0.6\n",
    "pval_threshold = 0.05\n",
    "min_group_percentage = 0.6\n",
    "ns_for_insignificant = False\n",
    "\n",
    "# Get paths\n",
    "path_prefix = \"./model_runs/_fullruns/\"\n",
    "path_suffix = f\"glmm/all_interactions_{rfe_with_interactions}-climate_interaction_{add_spei_temp_interaction}-climate_derivatives_{add_spei_temp_derivatives}/rfe_{do_rfe}/\"\n",
    "if do_rfe:\n",
    "    path_suffix += f\"best_model_{best_model_method}/\"\n",
    "\n",
    "print(f\"Saving to {path_prefix}/RUN/SPECIES/{path_suffix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ! TODO:\n",
    "# - Skipping model building still requires loading the best model and then deciding which to rerun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Species and Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_species = get_species_with_models(\"list\")\n",
    "\n",
    "top9 = final_species[:9]\n",
    "\n",
    "base_dir = \"./model_runs/_fullruns/\"\n",
    "models_dir = os.listdir(base_dir)\n",
    "models_dir = [m for m in models_dir if \"impurity\" in m]\n",
    "models_dir = sorted(models_dir)\n",
    "\n",
    "# Merge species and model lists into one df\n",
    "models_species = list(itertools.product(models_dir, final_species))\n",
    "df_in = pd.DataFrame(models_species, columns=[\"model\", \"species\"])\n",
    "df_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# ispecies = \"Juniperus communis\"\n",
    "# imodel = df_in.loc[0, \"model\"]\n",
    "\n",
    "# # x, y = glmm_run_per_species_and_model( # ! For debugging\n",
    "# glmm_run_per_species_and_model(\n",
    "#     ispecies,\n",
    "#     imodel,\n",
    "#     verbose=True,\n",
    "#     do_rfe=do_rfe,\n",
    "#     rfe_with_interactions=rfe_with_interactions,\n",
    "#     add_spei_temp_interaction=add_spei_temp_interaction,\n",
    "#     add_spei_temp_derivatives=add_spei_temp_derivatives,\n",
    "#     best_model_method=best_model_method,\n",
    "#     path_prefix=path_prefix,\n",
    "#     path_suffix=path_suffix,\n",
    "#     return_all=False,\n",
    "#     skip_if_exists=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utilities import glmm_wrapper_loop\n",
    "\n",
    "# # Run glmm fitting in parallel:\n",
    "# out = run_mp(\n",
    "#     glmm_wrapper_loop,\n",
    "#     arg_list=split_df_into_list_of_group_or_ns(df_in, \"model\"),\n",
    "#     num_cores=10,\n",
    "#     progress_bar=True,\n",
    "#     verbose=False,\n",
    "#     do_rfe=do_rfe,\n",
    "#     rfe_with_interactions=rfe_with_interactions,\n",
    "#     add_spei_temp_interaction=add_spei_temp_interaction,\n",
    "#     add_spei_temp_derivatives=add_spei_temp_derivatives,\n",
    "#     best_model_method=best_model_method,\n",
    "#     path_prefix=path_prefix,\n",
    "#     path_suffix=path_suffix,\n",
    "#     return_all=False,\n",
    "#     skip_if_exists=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! osascript -e 'tell app \"System Events\" to shut down'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GLMM Runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which models have NO model created\n",
    "i_missing = []\n",
    "i_success = []\n",
    "for i, row in df_in.reset_index(drop=True).iterrows():\n",
    "    # Check for summary file because it is the last that should be saved per run\n",
    "    path_glmm = f\"{path_prefix}/{row.model}/{row.species}/{path_suffix}/summary.csv\"\n",
    "    if not os.path.isfile(path_glmm):\n",
    "        i_missing.append(row)\n",
    "    else:\n",
    "        i_success.append(row)\n",
    "\n",
    "if i_missing.__len__() > 0:\n",
    "    print(f\"Missing {i_missing.__len__()} models\")\n",
    "    i_missing = pd.concat(i_missing)\n",
    "    i_missing = pd.DataFrame(\n",
    "        {\"model\": i_missing.model.values, \"species\": i_missing.species.values}\n",
    "    )\n",
    "    print(\n",
    "        f\"Missing models: {i_missing.shape[0]} from {i_missing.model.nunique()} models and {i_missing.species.nunique()} species\"\n",
    "    )\n",
    "else:\n",
    "    print(\"All models are present\")\n",
    "\n",
    "i_success = pd.concat(i_success)\n",
    "i_success = pd.DataFrame(\n",
    "    {\"model\": i_success.model.values, \"species\": i_success.species.values}\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Successful models: {i_success.shape[0]} from {i_success.model.nunique()} models and {i_success.species.nunique()} species\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop over missing models to see which cause errors\n",
    "# verbose = True\n",
    "# for i, row in i_missing.reset_index(drop=True).iterrows():\n",
    "#     if verbose:\n",
    "#         print(f\"ðŸŸ¡ Species: {row.species}\\t | Model: {row.model}\")\n",
    "\n",
    "#     if \"61\" in row.model:\n",
    "#         print(\"Skipping: Alnus incana 61\")\n",
    "#         continue\n",
    "\n",
    "#     glmm_wrapper(\n",
    "#         ispecies=row.species,\n",
    "#         imodel=row.model,\n",
    "#         base_dir=\"./model_runs/_fullruns\",\n",
    "#         return_all=False,\n",
    "#         verbose=False,\n",
    "#     )\n",
    "#     clear_output()\n",
    "#     if verbose:\n",
    "#         print(f\"ðŸŸ¡ Species: {row.species}\\t | Model: {row.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare RF and GLMM performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC-AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp_perf = []\n",
    "\n",
    "for i, row in i_success.iterrows():\n",
    "\n",
    "    # Check if roc auc files are there\n",
    "    path_rf = f\"./model_runs/_fullruns/{row.model}/{row.species}/final_model_roc_auc_prob-based.csv\"\n",
    "    path_glmm = f\"{path_prefix}/{row.model}/{row.species}/{path_suffix}/final_model_roc_auc_prob-based.csv\"\n",
    "\n",
    "    if not os.path.isfile(path_glmm):\n",
    "        print(f\"GLMM file missing for {row.species} - {row.model}\")\n",
    "        continue\n",
    "    if not os.path.isfile(path_rf):\n",
    "        raise ValueError(f\"RF file missing: {path_rf}\")\n",
    "\n",
    "    # Attach files\n",
    "    irf = pd.read_csv(path_rf)\n",
    "    irf[\"species\"] = row.species\n",
    "    irf[\"model\"] = \"rf\"\n",
    "    irf[\"run\"] = row.model\n",
    "\n",
    "    iglmm = pd.read_csv(path_glmm)\n",
    "    iglmm[\"species\"] = row.species\n",
    "    iglmm[\"model\"] = \"glmm\"\n",
    "    iglmm[\"run\"] = row.model\n",
    "\n",
    "    df_comp_perf.append(irf)\n",
    "    df_comp_perf.append(iglmm)\n",
    "\n",
    "for subset in [\"all\", \"top9\"]:\n",
    "\n",
    "    # Get data\n",
    "    df_plot = pd.concat(df_comp_perf)\n",
    "    df_plot = df_plot[df_plot[\"test_mean\"] > roc_threshold]\n",
    "    if subset == \"top9\":\n",
    "        df_plot = df_plot[df_plot[\"species\"].isin(top9)]\n",
    "\n",
    "    # Get mean and std for each model\n",
    "    metric_table = df_plot.groupby([\"model\"]).agg(\n",
    "        {\"test_mean\": \"mean\", \"test_sd\": \"mean\"}\n",
    "    )\n",
    "    metric_rf = metric_table.loc[\"rf\"]\n",
    "    metric_rf = f\"RF: {metric_rf.test_mean:.2f} Â± {metric_rf.test_sd:.2f}\"\n",
    "    metric_glmm = metric_table.loc[\"glmm\"]\n",
    "    metric_glmm = f\"GLMM: {metric_glmm.test_mean:.2f} Â± {metric_glmm.test_sd:.2f}\"\n",
    "\n",
    "    # Replace model names with metrics\n",
    "    df_plot[\"model\"] = df_plot[\"model\"].replace({\"rf\": metric_rf, \"glmm\": metric_glmm})\n",
    "\n",
    "    # Create a boxplot\n",
    "    plt.figure(figsize=(5, 12))\n",
    "    sns.boxplot(\n",
    "        data=df_plot,\n",
    "        y=\"species\",\n",
    "        x=\"test_mean\",\n",
    "        hue=\"model\",  # Different colors for each model\n",
    "        palette=\"Set2\",  # Change color palette as desired\n",
    "    )\n",
    "\n",
    "    # Add titles and labels\n",
    "    # plt.title(\"Boxplot of Test Mean by Species and Model\")\n",
    "    plt.xlabel(\"ROC AUC on Test\")\n",
    "    plt.ylabel(\"Species\")\n",
    "\n",
    "    # Rotate x-axis labels\n",
    "    # plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.xticks(fontsize=10, ha=\"right\")\n",
    "\n",
    "    # Show legend\n",
    "    plt.legend(title=None, loc=\"lower right\")\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "    # Verbose\n",
    "    print(\"Comparison of random forest and logistic glmm models:\")\n",
    "    print(metric_rf)\n",
    "    print(metric_glmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PR-AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate PR-AUC first\n",
    "# run_mp(\n",
    "#     run_prauc_for_rfs,\n",
    "#     split_df_into_list_of_group_or_ns(df_in, 10),\n",
    "#     progress_bar=True,\n",
    "#     num_cores=10,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp_perf = []\n",
    "\n",
    "for i, row in i_success.iterrows():\n",
    "\n",
    "    # Check if roc auc files are there\n",
    "    path_rf = f\"./model_runs/_fullruns/{row.model}/{row.species}/roc_auc_curves/final_model_pr_auc_prob-based.csv\"\n",
    "    path_glmm = f\"{path_prefix}/{row.model}/{row.species}/{path_suffix}/final_model_pr_auc_prob-based.csv\"\n",
    "\n",
    "    if not os.path.isfile(path_glmm):\n",
    "        print(f\"GLMM file missing for {row.species} - {row.model}\")\n",
    "        continue\n",
    "    if not os.path.isfile(path_rf):\n",
    "        raise ValueError(f\"RF file missing: {path_rf}\")\n",
    "\n",
    "    # Attach files\n",
    "    irf = pd.read_csv(path_rf)\n",
    "    irf[\"species\"] = row.species\n",
    "    irf[\"model\"] = \"rf\"\n",
    "    irf[\"run\"] = row.model\n",
    "\n",
    "    iglmm = pd.read_csv(path_glmm)\n",
    "    iglmm[\"species\"] = row.species\n",
    "    iglmm[\"model\"] = \"glmm\"\n",
    "    iglmm[\"run\"] = row.model\n",
    "\n",
    "    df_comp_perf.append(irf)\n",
    "    df_comp_perf.append(iglmm)\n",
    "\n",
    "for subset in [\"all\", \"top9\"]:\n",
    "\n",
    "    # Get data\n",
    "    df_plot = pd.concat(df_comp_perf)\n",
    "    # df_plot = df_plot[df_plot[\"test_mean\"] > roc_threshold]\n",
    "    if subset == \"top9\":\n",
    "        df_plot = df_plot[df_plot[\"species\"].isin(top9)]\n",
    "\n",
    "    # Get mean and std for each model\n",
    "    metric_table = df_plot.groupby([\"model\"]).agg(\n",
    "        {\"test_mean\": \"mean\", \"test_sd\": \"mean\"}\n",
    "    )\n",
    "    metric_rf = metric_table.loc[\"rf\"]\n",
    "    metric_rf = f\"RF: {metric_rf.test_mean:.2f} Â± {metric_rf.test_sd:.2f}\"\n",
    "    metric_glmm = metric_table.loc[\"glmm\"]\n",
    "    metric_glmm = f\"GLMM: {metric_glmm.test_mean:.2f} Â± {metric_glmm.test_sd:.2f}\"\n",
    "\n",
    "    # Replace model names with metrics\n",
    "    df_plot[\"model\"] = df_plot[\"model\"].replace({\"rf\": metric_rf, \"glmm\": metric_glmm})\n",
    "\n",
    "    # Create a boxplot\n",
    "    plt.figure(figsize=(5, 12))\n",
    "    sns.boxplot(\n",
    "        data=df_plot,\n",
    "        y=\"species\",\n",
    "        x=\"test_mean\",\n",
    "        hue=\"model\",  # Different colors for each model\n",
    "        palette=\"Set2\",  # Change color palette as desired\n",
    "    )\n",
    "\n",
    "    # Add titles and labels\n",
    "    # plt.title(\"Boxplot of Test Mean by Species and Model\")\n",
    "    plt.xlabel(\"PR AUC on Test Set\")\n",
    "    plt.ylabel(\"Species\")\n",
    "\n",
    "    # Rotate x-axis labels\n",
    "    # plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.xticks(ha=\"right\", fontsize=10)\n",
    "\n",
    "    # Show legend\n",
    "    plt.legend(title=None)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "    # Verbose\n",
    "    print(\"Comparison of random forest and logistic glmm models:\")\n",
    "    print(metric_rf)\n",
    "    print(metric_glmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable importance comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and concat all results\n",
    "\n",
    "df_all = []\n",
    "for ispecies in final_species:\n",
    "    for imodel in models_dir:\n",
    "\n",
    "        path = f\"{path_prefix}/{imodel}/{ispecies}/{path_suffix}/summary.csv\"\n",
    "\n",
    "        # Load if file exists\n",
    "        if os.path.isfile(path):\n",
    "            idf = pd.read_csv(\n",
    "                path,\n",
    "                index_col=0,\n",
    "            )[[\"Estimate\", \"P-val\", \"2.5_ci\", \"97.5_ci\", \"SE\"]]\n",
    "\n",
    "            # Generalize columns names based on category\n",
    "            idf[\"dataset\"] = idf.index.map(get_category_from_var_wrapper)\n",
    "            idf = idf.reset_index().rename({\"index\": \"variable\"}, axis=1)\n",
    "\n",
    "            # Add info\n",
    "            idf[\"species\"] = ispecies\n",
    "            idf[\"model\"] = imodel\n",
    "            idf = move_vars_to_front(idf, [\"species\", \"model\", \"dataset\", \"variable\"])\n",
    "            df_all.append(idf)\n",
    "        else:\n",
    "            pass\n",
    "            print(f\"Missing: {ispecies} - {imodel}\")\n",
    "\n",
    "\n",
    "# Load data\n",
    "df_vimp = pd.concat(df_all)\n",
    "df_vimp = df_vimp[[\"species\", \"model\", \"dataset\", \"Estimate\"]]\n",
    "\n",
    "# Take estimate as importance proxy by taking the absolute value\n",
    "df_vimp[\"Estimate\"] = df_vimp[\"Estimate\"].abs() * 100\n",
    "\n",
    "# Merge interaction variables\n",
    "df_vimp[\"dataset\"] = df_vimp[\"dataset\"].str.replace(\n",
    "    \"Interaction_SPEI_Temperature\", \"Interaction_Temperature_SPEI\"\n",
    ")\n",
    "\n",
    "# Take the mean per model-species-dataset combination (e.g. there are two temperature variables when linear and quad. are included)\n",
    "df_vimp = df_vimp.groupby([\"species\", \"model\", \"dataset\"]).mean().reset_index()\n",
    "\n",
    "# # Make wide df_vimp\n",
    "df_vimp = df_vimp.pivot(\n",
    "    index=[\"species\", \"model\"], columns=\"dataset\", values=\"Estimate\"\n",
    ").reset_index()\n",
    "\n",
    "# Drop intercept columns\n",
    "df_vimp = df_vimp.drop(\"Intercept\", axis=1)\n",
    "\n",
    "# For each row, divide the estimate by the sum of the estimates for that row\n",
    "df_vimp.iloc[:, 2:] = (\n",
    "    df_vimp.iloc[:, 2:].div(df_vimp.iloc[:, 2:].sum(axis=1), axis=0) * 100\n",
    ")\n",
    "\n",
    "# Display\n",
    "df_vimp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import ax_dataset_boxplot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax_dataset_boxplot(\n",
    "    ax,\n",
    "    df_vimp,\n",
    "    df_vimp.columns[2:].tolist(),\n",
    "    base_fontsize=11,\n",
    "    pos_spei=4,\n",
    "    pos_temp=5,\n",
    "    all_or_top9=\"top9\",\n",
    ")\n",
    "ax.set_xlim(0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate climate effect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At model-level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speitemp_list = []\n",
    "\n",
    "for i, row in i_success.iterrows():\n",
    "\n",
    "    # Check if roc auc files are there\n",
    "    path_glmm = f\"{path_prefix}/{row.model}/{row.species}/{path_suffix}/summary.csv\"\n",
    "    path_perf = f\"{path_prefix}/{row.model}/{row.species}/{path_suffix}/final_model_roc_auc_prob-based.csv\"\n",
    "\n",
    "    if not os.path.isfile(path_glmm) or not os.path.isfile(path_perf):\n",
    "        print(f\" - ðŸš¨ GLMM files incomplete for {row.species} - {row.model}\")\n",
    "        continue\n",
    "\n",
    "    # Load data\n",
    "    iper = pd.read_csv(path_perf)\n",
    "    isry = pd.read_csv(path_glmm, index_col=0)\n",
    "    var_spei = glmm_get_spei_var(isry.index)\n",
    "    var_temp = glmm_get_temp_var(isry.index)\n",
    "\n",
    "    if var_spei is None:\n",
    "        esti_spei = None\n",
    "        sign_spei = None\n",
    "        dire_spei = None\n",
    "        pval_spei = None\n",
    "        change_spei = None\n",
    "    else:\n",
    "        esti_spei = isry.loc[[var_spei]][\"Estimate\"].values[0]\n",
    "        sign_spei = isry.loc[[var_spei]][\"Sig\"].values[0]\n",
    "        dire_spei = np.sign(isry.loc[[var_spei]][\"Estimate\"].values[0])\n",
    "        pval_spei = isry.loc[[var_spei]][\"P-val\"].values[0]\n",
    "\n",
    "        if pval_spei < pval_threshold:\n",
    "            if dire_spei > 0:\n",
    "                change_spei = \"wetter\"\n",
    "            else:\n",
    "                change_spei = \"drier\"\n",
    "        else:\n",
    "            change_spei = \"ns\"\n",
    "\n",
    "    if var_temp is None:\n",
    "        esti_temp = None\n",
    "        sign_temp = None\n",
    "        dire_temp = None\n",
    "        pval_temp = None\n",
    "        change_temp = None\n",
    "    else:\n",
    "        esti_temp = isry.loc[[var_temp]][\"Estimate\"].values[0]\n",
    "        sign_temp = isry.loc[[var_temp]][\"Sig\"].values[0]\n",
    "        dire_temp = np.sign(isry.loc[[var_temp]][\"Estimate\"].values[0])\n",
    "        pval_temp = isry.loc[[var_temp]][\"P-val\"].values[0]\n",
    "\n",
    "        if pval_temp < pval_threshold:\n",
    "            if dire_temp > 0:\n",
    "                change_temp = \"warmer\"\n",
    "            else:\n",
    "                change_temp = \"cooler\"\n",
    "        else:\n",
    "            change_temp = \"ns\"\n",
    "\n",
    "    # Attach temp and spei information\n",
    "    df_speitemp_list.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"species\": row.species,\n",
    "                \"run\": row.model.split(\" -\")[0].split(\"_\")[1],\n",
    "                \"spei\": var_spei,\n",
    "                \"sign_spei\": sign_spei,\n",
    "                \"dire_spei\": dire_spei,\n",
    "                \"pval_spei\": pval_spei,\n",
    "                \"change_spei\": change_spei,\n",
    "                \"temp\": var_temp,\n",
    "                \"sign_temp\": sign_temp,\n",
    "                \"dire_temp\": dire_temp,\n",
    "                \"pval_temp\": pval_temp,\n",
    "                \"change_temp\": change_temp,\n",
    "                \"test_roc_auc\": iper[\"test_mean\"].values[0],\n",
    "            },\n",
    "            index=[0],\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Get dictionary\n",
    "dict_spei = {\n",
    "    +1: \"drier\",\n",
    "    -1: \"wetter\",\n",
    "}\n",
    "\n",
    "dict_temp = {\n",
    "    +1: \"warmer\",\n",
    "    -1: \"cooler\",\n",
    "}\n",
    "\n",
    "dict_ns = {\n",
    "    \"ns_ns\": \"ns\",\n",
    "    \"ns_wetter\": \"ns\",\n",
    "    \"ns_drier\": \"ns\",\n",
    "    \"warmer_ns\": \"ns\",\n",
    "    \"cooler_ns\": \"ns\",\n",
    "    \"warmer_wetter\": \"warmer_wetter\",\n",
    "    \"warmer_drier\": \"warmer_drier\",\n",
    "    \"cooler_wetter\": \"cooler_wetter\",\n",
    "    \"cooler_drier\": \"cooler_drier\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlist data\n",
    "df_pattern_per_model = pd.concat(df_speitemp_list)\n",
    "df_pattern_per_model[\"change_spei_all\"] = df_pattern_per_model[\"dire_spei\"].map(\n",
    "    dict_spei\n",
    ")\n",
    "df_pattern_per_model[\"change_temp_all\"] = df_pattern_per_model[\"dire_temp\"].map(\n",
    "    dict_temp\n",
    ")\n",
    "df_pattern_per_model[\"change_both_all\"] = (\n",
    "    df_pattern_per_model[\"change_temp_all\"]\n",
    "    + \"_\"\n",
    "    + df_pattern_per_model[\"change_spei_all\"]\n",
    ")\n",
    "df_pattern_per_model[\"change_both_sign\"] = (\n",
    "    df_pattern_per_model[\"change_temp\"] + \"_\" + df_pattern_per_model[\"change_spei\"]\n",
    ")\n",
    "df_pattern_per_model[\"change_both_sign\"] = df_pattern_per_model[\"change_both_sign\"].map(\n",
    "    dict_ns\n",
    ")\n",
    "\n",
    "\n",
    "for all_or_top9 in [\"all\", \"top9\"]:\n",
    "    if all_or_top9 == \"top9\":\n",
    "        text = \"Top 9 species\"\n",
    "        df_tmp = df_pattern_per_model.query(\"species in @top9\").copy()\n",
    "    else:\n",
    "        df_tmp = df_pattern_per_model.copy()\n",
    "        text = \"All species\"\n",
    "\n",
    "    display(f\"----- ðŸš¨ {text} ------\")\n",
    "\n",
    "    print(\"--- Change patterns all ---\")\n",
    "    display(df_tmp.change_temp_all.value_counts(normalize=True).sort_values().round(2))\n",
    "    display(df_tmp.change_spei_all.value_counts(normalize=True).sort_values().round(2))\n",
    "    display(df_tmp.change_both_all.value_counts(normalize=True).sort_values().round(2))\n",
    "\n",
    "    print(f\"--- Change patterns significant at p = {pval_threshold}---\")\n",
    "    display(df_tmp.change_temp.value_counts(normalize=True).sort_values().round(2))\n",
    "    display(df_tmp.change_spei.value_counts(normalize=True).sort_values().round(2))\n",
    "    print(f\"- Both with ns\")\n",
    "    display(df_tmp.change_both_sign.value_counts(normalize=True).sort_values().round(2))\n",
    "    print(f\"- Both without ns\")\n",
    "    display(\n",
    "        df_tmp.query(\"change_both_sign != 'ns'\")\n",
    "        .change_both_sign.value_counts(normalize=True)\n",
    "        .sort_values()\n",
    "        .round(2)\n",
    "    )\n",
    "\n",
    "    # fx(df_tmp, \"wetter\")\n",
    "    # fx(df_tmp, \"drier\")\n",
    "    # fx(df_tmp, \"warmer\")\n",
    "    # fx(df_tmp, \"cooler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_nonsignificant = True\n",
    "\n",
    "if keep_nonsignificant:\n",
    "    tmp_suffix = \"_all\"\n",
    "else:\n",
    "    tmp_suffix = \"\"\n",
    "\n",
    "df_res_lm = (\n",
    "    df_pattern_per_model.sort_values(\"species\")\n",
    "    .rename(\n",
    "        columns={\n",
    "            f\"change_spei{tmp_suffix}\": \"response_spei\",\n",
    "            f\"change_temp{tmp_suffix}\": \"response_temp\",\n",
    "        }\n",
    "    )\n",
    "    .query(\"test_roc_auc > @roc_threshold\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# display(df_res_lm)\n",
    "\n",
    "# Group by species and spei/temp variables\n",
    "df_res_lm_group = (\n",
    "    df_res_lm.dropna(subset=[\"response_spei\", \"response_temp\"])\n",
    "    # .query(\"dire_spei == 0 or dire_temp == 0\")\n",
    "    .groupby([\"species\", \"spei\", \"temp\"])\n",
    ")\n",
    "\n",
    "df_list = []\n",
    "\n",
    "i = 0\n",
    "ispecies = \"\"\n",
    "\n",
    "for group in df_res_lm_group.groups:\n",
    "\n",
    "    # Increment group counter\n",
    "    if ispecies == group[0]:\n",
    "        group_counter = group_counter + 1\n",
    "    else:\n",
    "        group_counter = 1\n",
    "        ispecies = group[0]\n",
    "\n",
    "    # Get group\n",
    "    df_group = df_res_lm_group.get_group(group)\n",
    "    # Get group size\n",
    "    group_size = df_group.shape[0]\n",
    "    # Get pattern percentages\n",
    "    spei_pattern, spei_value = get_var_and_val(df_group, \"spei\", min_group_percentage)\n",
    "    temp_pattern, temp_value = get_var_and_val(df_group, \"temp\", min_group_percentage)\n",
    "\n",
    "    idf = pd.DataFrame(\n",
    "        {\n",
    "            \"species\": group[0],\n",
    "            \"spei\": group[1],\n",
    "            \"temp\": group[2],\n",
    "            \"group\": group_counter,\n",
    "            \"group_size\": group_size,\n",
    "            \"response_spei\": spei_pattern,\n",
    "            \"response_temp\": temp_pattern,\n",
    "            \"perc_spei\": spei_value,\n",
    "            \"perc_temp\": temp_value,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    df_list.append(idf)\n",
    "    # display(idf)\n",
    "    # display(df_group)\n",
    "\n",
    "\n",
    "# pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_patterns = pd.concat(df_list)\n",
    "df_patterns[\"change\"] = (\n",
    "    df_patterns[\"response_temp\"] + \"_\" + df_patterns[\"response_spei\"]\n",
    ")\n",
    "\n",
    "# If ns is in change, then it is ns\n",
    "df_patterns[\"change\"] = df_patterns[\"change\"].apply(lambda x: \"ns\" if \"ns\" in x else x)\n",
    "df_patterns.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all species\n",
    "pattern_both = plot_pattern_dist(df_patterns, \"change\")\n",
    "pattern_spei = plot_pattern_dist(df_patterns, \"response_spei\")\n",
    "pattern_temp = plot_pattern_dist(df_patterns, \"response_temp\")\n",
    "\n",
    "patterns_merged_allspecies = pd.concat(\n",
    "    [\n",
    "        pattern_temp.replace({\"ns\": \"ns (temp)\"}),\n",
    "        pattern_spei.replace({\"ns\": \"ns (spei)\"}),\n",
    "        pattern_both,\n",
    "    ],\n",
    "    axis=0,\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# For all species\n",
    "pattern_both = plot_pattern_dist(df_patterns.query(\"species in @top9\"), \"change\")\n",
    "pattern_spei = plot_pattern_dist(df_patterns.query(\"species in @top9\"), \"response_spei\")\n",
    "pattern_temp = plot_pattern_dist(df_patterns.query(\"species in @top9\"), \"response_temp\")\n",
    "\n",
    "patterns_merged_top9 = pd.concat(\n",
    "    [\n",
    "        pattern_temp.replace({\"ns\": \"ns (temp)\"}),\n",
    "        pattern_spei.replace({\"ns\": \"ns (spei)\"}),\n",
    "        pattern_both,\n",
    "    ],\n",
    "    axis=0,\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_with_grouped_response = pd.merge(\n",
    "    df_res_lm[[\"species\", \"spei\", \"temp\", \"run\", \"pval_spei\", \"pval_temp\"]],\n",
    "    df_patterns[\n",
    "        [\n",
    "            \"species\",\n",
    "            \"spei\",\n",
    "            \"temp\",\n",
    "            \"group_size\",\n",
    "            \"response_temp\",\n",
    "            \"response_spei\",\n",
    "            \"change\",\n",
    "        ]\n",
    "    ],\n",
    "    how=\"left\",\n",
    "    on=[\"species\", \"spei\", \"temp\"],\n",
    ")\n",
    "\n",
    "# Keep original pval for checking later on\n",
    "df_models_with_grouped_response[\"pval_spei_org\"] = (\n",
    "    df_models_with_grouped_response[\"pval_spei\"].copy().round(3)\n",
    ")\n",
    "df_models_with_grouped_response[\"pval_temp_org\"] = (\n",
    "    df_models_with_grouped_response[\"pval_temp\"].copy().round(3)\n",
    ")\n",
    "\n",
    "# Attach pval for both spei and temp\n",
    "df_models_with_grouped_response[\"pval_spei\"] = df_models_with_grouped_response[\n",
    "    \"pval_spei\"\n",
    "].fillna(1)\n",
    "df_models_with_grouped_response[\"pval_spei\"] = (\n",
    "    df_models_with_grouped_response[\"pval_spei\"] < pval_threshold\n",
    ")\n",
    "df_models_with_grouped_response[\"pval_temp\"] = df_models_with_grouped_response[\n",
    "    \"pval_temp\"\n",
    "].fillna(1)\n",
    "\n",
    "df_models_with_grouped_response[\"pval_temp\"] = (\n",
    "    df_models_with_grouped_response[\"pval_temp\"] < pval_threshold\n",
    ")\n",
    "\n",
    "df_models_with_grouped_response[\"pval_both\"] = (\n",
    "    df_models_with_grouped_response[\"pval_spei\"] == True\n",
    ") & (df_models_with_grouped_response[\"pval_temp\"] == True)\n",
    "\n",
    "# Attach spei_temp pair\n",
    "df_models_with_grouped_response[\"spei_temp\"] = (\n",
    "    df_models_with_grouped_response[\"spei\"]\n",
    "    + \"-\"\n",
    "    + df_models_with_grouped_response[\"temp\"]\n",
    ")\n",
    "\n",
    "df_models_with_grouped_response.sort_values(\n",
    "    [\"species\", \"group_size\", \"spei_temp\"], ascending=[True, False, True]\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ! Assess significance of features\n",
    "list_all = []\n",
    "list_top9 = []\n",
    "\n",
    "for pattern in [\n",
    "    \"warmer\",\n",
    "    \"cooler\",\n",
    "    \"wetter\",\n",
    "    \"drier\",\n",
    "    \"warmer_wetter\",\n",
    "    \"warmer_drier\",\n",
    "    \"cooler_wetter\",\n",
    "    \"cooler_drier\",\n",
    "    \"ns (temp)\",\n",
    "    \"ns (spei)\",\n",
    "    \"ns\",\n",
    "]:\n",
    "    if pattern == \"warmer\" or pattern == \"cooler\" or pattern == \"ns (temp)\":\n",
    "        var_all = \"response_temp\"\n",
    "        var_sign = \"pval_temp\"\n",
    "        search_pattern = pattern\n",
    "    elif pattern == \"wetter\" or pattern == \"drier\" or pattern == \"ns (spei)\":\n",
    "        var_all = \"response_spei\"\n",
    "        var_sign = \"pval_spei\"\n",
    "        search_pattern = pattern\n",
    "    else:\n",
    "        var_all = \"change\"\n",
    "        var_sign = \"pval_both\"\n",
    "        search_pattern = pattern\n",
    "\n",
    "    if \"ns\" in pattern:\n",
    "        search_pattern = \"ns\"\n",
    "\n",
    "    # All\n",
    "    xxx = df_models_with_grouped_response.query(f\"{var_all} == '{search_pattern}'\")\n",
    "    xxx = xxx[var_sign].value_counts(normalize=True).sort_index()\n",
    "    xxx[\"response\"] = var_all\n",
    "    xxx[\"pattern\"] = pattern\n",
    "    xxx = xxx.to_frame().T\n",
    "    list_all.append(xxx)\n",
    "\n",
    "    # Top9\n",
    "    xxx = df_models_with_grouped_response.query(\n",
    "        f\"{var_all} == '{search_pattern}' and species in @top9\"\n",
    "    )\n",
    "    xxx = xxx[var_sign].value_counts(normalize=True).sort_index()\n",
    "    xxx[\"response\"] = var_all\n",
    "    xxx[\"pattern\"] = pattern\n",
    "    xxx = xxx.to_frame().T\n",
    "    list_top9.append(xxx)\n",
    "\n",
    "\n",
    "df_significance_all_species = pd.concat(list_all).reset_index(drop=True)\n",
    "df_significance_all_species = df_significance_all_species.drop(\n",
    "    columns=[\n",
    "        \"response\",\n",
    "        # \"pval_spei\",\n",
    "    ]\n",
    ").rename(columns={False: \"ns\", True: \"sig\"})\n",
    "\n",
    "df_significance_top9 = pd.concat(list_top9).reset_index(drop=True)\n",
    "df_significance_top9 = df_significance_top9.drop(\n",
    "    columns=[\n",
    "        \"response\",\n",
    "        # \"pval_spei\",\n",
    "    ]\n",
    ").rename(columns={False: \"ns\", True: \"sig\"})\n",
    "\n",
    "# Show\n",
    "display(df_significance_all_species)\n",
    "display(df_significance_top9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Get final df for plotting\n",
    "for all_or_top9 in [\"all\", \"top9\"]:\n",
    "    print(f\" --- {all_or_top9} ---\")\n",
    "\n",
    "    df_tmp = df_vimp.copy()\n",
    "    if all_or_top9 == \"top9\":\n",
    "        df_tmp = df_tmp[df_tmp[\"species\"].isin(top9)]\n",
    "\n",
    "    if all_or_top9 == \"all\":\n",
    "        df_plot = pd.merge(\n",
    "            patterns_merged_allspecies,\n",
    "            df_significance_all_species,\n",
    "            left_on=\"change_simple\",\n",
    "            right_on=\"pattern\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        left_ylim = 60\n",
    "        ytick_labels = [\n",
    "            \"Warmer\".title(),\n",
    "            \"Cooler\".title(),\n",
    "            \"Other\".title(),\n",
    "            \"Drier\".title(),\n",
    "            \"Wetter\".title(),\n",
    "            \"Other\".title(),\n",
    "            \"Warmer + Drier\".title(),\n",
    "            \"Warmer + Wetter\".title(),\n",
    "            \"Cooler + Drier\".title(),\n",
    "            \"Cooler + Wetter\".title(),\n",
    "            \"Other\".title(),\n",
    "        ]\n",
    "    else:\n",
    "        df_plot = pd.merge(\n",
    "            patterns_merged_top9,\n",
    "            df_significance_top9,\n",
    "            left_on=\"change_simple\",\n",
    "            right_on=\"pattern\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        left_ylim = 60\n",
    "\n",
    "    # Split group size into ns and sig\n",
    "    df_plot[\"perc_sign\"] = df_plot[\"group_size_rel\"] * (1 - df_plot[\"ns\"])\n",
    "    df_plot[\"perc_ns\"] = df_plot[\"group_size_rel\"] * df_plot[\"ns\"]\n",
    "\n",
    "    # Fix the perc_xxx columns where ns was NA. FIll with group_size_rel\n",
    "    df_plot[\"perc_sign\"] = df_plot[\"perc_sign\"].fillna(df_plot[\"group_size_rel\"])\n",
    "    df_plot[\"perc_ns\"] = df_plot[\"perc_ns\"].fillna(0)\n",
    "\n",
    "    # Switch ns for unclear\n",
    "    df_plot[\"change_simple\"] = df_plot[\"change_simple\"].replace(\n",
    "        {\"ns\": \"unclear\", \"ns (spei)\": \"unclear (spei)\", \"ns (temp)\": \"unclear (temp)\"}\n",
    "    )\n",
    "\n",
    "    # Show\n",
    "    display(\n",
    "        df_plot[\n",
    "            [\n",
    "                \"change_simple\",\n",
    "                \"group_size_rel\",\n",
    "                \"pattern\",\n",
    "                \"ns\",\n",
    "                \"sig\",\n",
    "                \"perc_sign\",\n",
    "                \"perc_ns\",\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # ! Make Plot\n",
    "    # filedir = f\"{dir_patterns}/fig_dataset_pattern\"\n",
    "    filedir = f\"test\"\n",
    "    os.makedirs(filedir, exist_ok=True)\n",
    "    color_temp = \"#77422C\"\n",
    "    color_spei = \"#D1A289\"\n",
    "    color_rest = \"lightgrey\"\n",
    "    color_wd = sns.color_palette(\"Reds\", 3)[-1]\n",
    "    color_ww = sns.color_palette(\"Blues\", 3)[-1]\n",
    "    color_other = \"lightgrey\"\n",
    "\n",
    "    plot_bars_dataset_pattern(\n",
    "        df_plot,\n",
    "        df_tmp,\n",
    "        all_or_top9=all_or_top9,\n",
    "        color_temp=color_temp,\n",
    "        color_spei=color_spei,\n",
    "        color_rest=color_rest,\n",
    "        color_wd=color_wd,\n",
    "        color_ww=color_ww,\n",
    "        color_other=color_other,\n",
    "        filepath=f\"{filedir}/{all_or_top9}.png\",\n",
    "        ytick_labels=ytick_labels,\n",
    "        left_ylim=left_ylim,\n",
    "    )\n",
    "\n",
    "    # ! Importance distribution\n",
    "    df_tmp = df_tmp.drop(columns=[\"species\", \"model\"]).mean()\n",
    "    imp_stand = (\n",
    "        df_tmp[\"Light Competition\"]\n",
    "        + df_tmp[\"Species Competition\"]\n",
    "        + df_tmp[\"Stand Structure\"]\n",
    "        + df_tmp[\"Tree Size\"]\n",
    "    ).round(0)\n",
    "\n",
    "    imp_climate = (df_tmp[\"Temperature\"] + df_tmp[\"SPEI\"]).round(2)\n",
    "    imp_soil = (df_tmp[\"Soil Fertility\"] + df_tmp[\"Soil Water Conditions\"]).round(0)\n",
    "    imp_ndvi = (df_tmp[\"NDVI\"]).round(0)\n",
    "\n",
    "    display(df_tmp.round(2).sort_values(ascending=False))\n",
    "    print(f\"Sum of Stand-describing variables: {imp_stand}\")\n",
    "    print(f\"Sum of Climate-describing variables: {imp_climate}\")\n",
    "    print(f\"Sum of Soil-describing variables: {imp_soil}\")\n",
    "    print(f\"Sum of NDVI variables: {imp_ndvi}\\n\\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    patterns_merged_allspecies,\n",
    "    df_significance_all_species,\n",
    "    left_on=\"change_simple\",\n",
    "    right_on=\"pattern\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    patterns_merged_top9,\n",
    "    df_significance_top9,\n",
    "    left_on=\"change_simple\",\n",
    "    right_on=\"pattern\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_significance_top9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_significance_all_species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
