{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Forest Structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../../src\")\n",
    "from imports import *\n",
    "\n",
    "init_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information from Alive Trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all alive trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NFI data\n",
    "nfi_raw = get_final_nfi_data_for_analysis()\n",
    "\n",
    "# Focus only on trees that were alive at first visit\n",
    "nfi_raw = nfi_raw[nfi_raw[\"tree_state_1\"] == \"alive\"]\n",
    "\n",
    "# Number of trees and sites\n",
    "print(\"\\nSubsetting trees that were alive at first visit:\")\n",
    "print(\"\\tNumber of trees:\", nfi_raw.tree_id.nunique())\n",
    "print(\"\\tNumber of sites:\", nfi_raw.idp.nunique())\n",
    "\n",
    "# Keep only relevant columns\n",
    "subset = nfi_raw[\n",
    "    [\n",
    "        \"campagne_1\",\n",
    "        \"idp\",\n",
    "        \"tree_id\",\n",
    "        \"genus_lat\",\n",
    "        \"species_lat\",\n",
    "        \"species_lat2\",\n",
    "        \"tree_height_class\",\n",
    "        \"tree_circumference_class\",\n",
    "        \"espar\",\n",
    "        \"espar_red\",\n",
    "        \"tree_state_1\",\n",
    "        \"tree_state_2\",\n",
    "        \"tree_state_change\",\n",
    "        \"lib\",\n",
    "        \"c13_1\",\n",
    "        \"c13_rel\",\n",
    "        \"ba_1\",\n",
    "        \"dbh_1\",\n",
    "        \"ir5\",\n",
    "        \"htot_final\",  # Using mix of measured and RF-predicted values!\n",
    "        \"simplif\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Fix formatting of columns\n",
    "subset.loc[:, \"genus_lat\"] = subset[\"genus_lat\"].astype(str)\n",
    "subset.loc[:, \"species_lat\"] = subset[\"species_lat\"].astype(str)\n",
    "\n",
    "subset.loc[:, \"lib\"] = subset[\"lib\"].fillna(0)\n",
    "subset.loc[:, \"htot_final\"] = subset[\"htot_final\"].fillna(0)\n",
    "\n",
    "print(subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Site-Level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom_genu = get_dominant_species(subset, \"genus_lat\")\n",
    "dom_spec = get_dominant_species(subset, \"species_lat\")\n",
    "dom_spec2 = get_dominant_species(subset, \"species_lat2\")\n",
    "dom_htot = get_dominant_species(subset, \"tree_height_class\")\n",
    "dom_circ = get_dominant_species(subset, \"tree_circumference_class\")\n",
    "# dom_espa = get_dominant_species(subset, \"espar\")\n",
    "# dom_espared = get_dominant_species(subset, \"espar_red\")\n",
    "df_dom = (\n",
    "    dom_genu.merge(dom_spec, on=\"idp\", how=\"left\")\n",
    "    .merge(dom_spec2, on=\"idp\", how=\"left\")\n",
    "    .merge(dom_htot, on=\"idp\", how=\"left\")\n",
    "    .merge(dom_circ, on=\"idp\", how=\"left\")\n",
    ")\n",
    "df_dom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree-Level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate competition metrics (~20 minutes)\n",
    "df_comp = calculate_competition_metrics_mp(subset, tree_size_var=\"htot_final\")\n",
    "\n",
    "# Check whether tree belongs to dominant species\n",
    "dom_spec2 = get_dominant_species(subset, \"species_lat2\")\n",
    "df_dom_tree = pd.merge(\n",
    "    subset[[\"idp\", \"tree_id\", \"species_lat2\"]], dom_spec2, how=\"left\", on=\"idp\"\n",
    ")\n",
    "df_dom_tree[\"belongs_to_dom_spec\"] = (\n",
    "    df_dom_tree[\"species_lat2\"] == df_dom_tree[\"dom_species_lat2\"]\n",
    ").astype(int)\n",
    "\n",
    "df_dom_tree = df_dom_tree[[\"tree_id\", \"belongs_to_dom_spec\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean dbh per site\n",
    "df_dbh = (\n",
    "    subset.groupby(\"idp\")[\"dbh_1\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"dbh_1\": \"mean_dbh\"})\n",
    ")\n",
    "\n",
    "df_dbh = pd.merge(subset[[\"idp\", \"tree_id\"]], df_dbh, how=\"left\", on=\"idp\")\n",
    "\n",
    "# Calculate trees per site\n",
    "df_trees = (\n",
    "    subset.groupby(\"idp\")[\"tree_id\"]\n",
    "    .count()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"tree_id\": \"num_trees\"})\n",
    ")\n",
    "\n",
    "df_trees = df_trees.merge(df_dbh, how=\"left\", on=\"idp\")\n",
    "df_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes together\n",
    "df_tree_tmp = df_trees.merge(df_comp, how=\"left\", on=\"tree_id\").merge(\n",
    "    df_dom_tree, how=\"left\", on=\"tree_id\"\n",
    ")\n",
    "\n",
    "df_tree_tmp = move_vars_to_front(df_tree_tmp, [\"tree_id\", \"idp\"])\n",
    "\n",
    "# Save dataframe\n",
    "df_tree_tmp.to_feather(here(\"data/final/predictor_datasets/forest_competition.feather\"))\n",
    "\n",
    "df_tree_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini Inequality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gini = calculate_gini_coefficient(subset, \"idp\", \"ba_1\").sort_values(\"gini_ba_1\")\n",
    "df_gini.sort_values(\"gini_ba_1\", ascending=False)\n",
    "df_gini.to_feather(\"../../data/final/predictor_datasets/forest_gini.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biodiversity Indeces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ! Compare the two diversity indices\n",
    "\n",
    "pick_metric = \"species_lat2\"\n",
    "\n",
    "simpson = calculate_simpson_diversity(subset, \"idp\", pick_metric)\n",
    "shannon = calculate_shannon_diversity(subset, \"idp\", \"tree_id\", pick_metric)\n",
    "\n",
    "# Merge the two diversity indices\n",
    "diversity = pd.merge(simpson, shannon, on=\"idp\", how=\"left\")\n",
    "diversity\n",
    "\n",
    "# Scale each index to a range of 0-1\n",
    "diversity[f\"biodiv_simpson_score_{pick_metric}\"] = (\n",
    "    diversity[f\"biodiv_simpson_score_{pick_metric}\"]\n",
    "    - diversity[f\"biodiv_simpson_score_{pick_metric}\"].min()\n",
    ") / (\n",
    "    diversity[f\"biodiv_simpson_score_{pick_metric}\"].max()\n",
    "    - diversity[f\"biodiv_simpson_score_{pick_metric}\"].min()\n",
    ")\n",
    "\n",
    "diversity[f\"biodiv_shan_{pick_metric}\"] = (\n",
    "    diversity[f\"biodiv_shan_{pick_metric}\"]\n",
    "    - diversity[f\"biodiv_shan_{pick_metric}\"].min()\n",
    ") / (\n",
    "    diversity[f\"biodiv_shan_{pick_metric}\"].max()\n",
    "    - diversity[f\"biodiv_shan_{pick_metric}\"].min()\n",
    ")\n",
    "\n",
    "# Plot the diversity indices\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Add 1 to 1 line\n",
    "ax.plot([0, 1], [0, 1], color=\"black\", linestyle=\"--\")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=diversity,\n",
    "    x=f\"biodiv_simpson_score_{pick_metric}\",\n",
    "    y=f\"biodiv_shan_{pick_metric}\",\n",
    "    ax=ax,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of species per site\n",
    "df_spec_per_site = subset.groupby(\"idp\")[\"species_lat2\"].nunique().reset_index()\n",
    "df_spec_per_site = df_spec_per_site.rename(columns={\"species_lat2\": \"num_species\"})\n",
    "\n",
    "# Clean names\n",
    "simpson = simpson.rename(\n",
    "    columns={\"biodiv_simpson_score_species_lat2\": \"simpson_species\"}\n",
    ")[[\"idp\", \"simpson_species\"]]\n",
    "shannon = shannon.rename(columns={\"biodiv_shan_species_lat2\": \"shannon_species\"})[\n",
    "    [\"idp\", \"shannon_species\"]\n",
    "]\n",
    "\n",
    "df_diversity = pd.merge(simpson, shannon, on=\"idp\", how=\"left\").merge(\n",
    "    df_spec_per_site, on=\"idp\", how=\"left\"\n",
    ")\n",
    "df_diversity\n",
    "\n",
    "df_diversity.to_feather(\n",
    "    \"../../data/final/predictor_datasets/forest_biodiversity.feather\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Thinning Line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD SUBSET FROM ABOVE!\n",
    "# ! Number of trees per hectare\n",
    "\n",
    "\n",
    "# Functions\n",
    "def trees_per_hectare(count_trees, radius):\n",
    "    area_ha = (radius / 100) ** 2 * 3.14159\n",
    "    trees_per_ha = count_trees / area_ha\n",
    "    return trees_per_ha\n",
    "\n",
    "\n",
    "# Inputs\n",
    "radius_small = 6\n",
    "radius_medium = 9\n",
    "radius_large = 15\n",
    "\n",
    "# Group by 'idp' and 'tree_circumference_class', then count the occurrences\n",
    "counts = (\n",
    "    subset.groupby([\"idp\", \"tree_circumference_class\"], observed=False)\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "# Calculate trees per hectare for each circumference class\n",
    "trees_per_hectare_small = trees_per_hectare(counts[\"small\"], radius_small)\n",
    "trees_per_hectare_medium = trees_per_hectare(counts[\"medium\"], radius_medium)\n",
    "trees_per_hectare_large = trees_per_hectare(counts[\"large\"], radius_large)\n",
    "\n",
    "# Calculate total trees per hectare for each site\n",
    "total_trees_per_hectare = (\n",
    "    trees_per_hectare_small + trees_per_hectare_medium + trees_per_hectare_large\n",
    ")\n",
    "\n",
    "# Create the output DataFrame\n",
    "df_out = pd.DataFrame(\n",
    "    {\"idp\": counts.index, \"num_trees_per_ha\": total_trees_per_hectare}\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# ! DBH per plot\n",
    "# Calculate mean DBH normal\n",
    "df_meandbh = subset.groupby(\"idp\")[\"dbh_1\"].mean().reset_index(name=\"dbh_1\")\n",
    "df_meandbh[\"dbh_1\"] = df_meandbh[\"dbh_1\"] * 100\n",
    "\n",
    "# Calculate mean DBH squared\n",
    "subset[\"dbh_1_sq\"] = (subset[\"dbh_1\"] * 100) ** 2\n",
    "df_meandbh2 = subset.groupby(\"idp\")[\"dbh_1_sq\"].mean().reset_index(name=\"dbh_1_sq\")\n",
    "df_meandbh2[\"dbh_1_sq\"] = df_meandbh2[\"dbh_1_sq\"] ** 0.5\n",
    "\n",
    "df_meandbh = pd.merge(df_meandbh, df_meandbh2, on=\"idp\", how=\"left\")\n",
    "\n",
    "# Attach variables directly to be used in the model\n",
    "\n",
    "\n",
    "# ! Merge them\n",
    "df_stl = pd.merge(df_meandbh, df_out, on=\"idp\", how=\"left\")\n",
    "\n",
    "# ! Attach dominant species and its \"purity\"\n",
    "df_stl = df_stl.merge(\n",
    "    get_dominant_species(subset, \"species_lat2\"), how=\"left\", on=\"idp\"\n",
    ")\n",
    "\n",
    "df_stl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "above_90percent = (\n",
    "    df_stl.query(\"ba_1_perc_of_species_lat2 >= 90\").shape[0] / df_stl.shape[0] * 100\n",
    ")\n",
    "print(f\"{round(above_90percent)}% of all sites have a purity of at least 90%\")\n",
    "display(df_stl.ba_1_perc_of_species_lat2.describe())\n",
    "df_stl.ba_1_perc_of_species_lat2.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load empirical models for self-thinning lines\n",
    "stl_lin = pd.read_excel(\n",
    "    \"../../docs/charru2012significant_self-thinning-lines.xlsx\",\n",
    "    sheet_name=\"Table 2 - Linear Models\",\n",
    ")\n",
    "\n",
    "stl_cur = (\n",
    "    pd.read_excel(\n",
    "        \"../../docs/charru2012significant_self-thinning-lines.xlsx\",\n",
    "        sheet_name=\"Table 5 - Curvilinear Models\",\n",
    "    )\n",
    "    .dropna()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "display(stl_lin)\n",
    "display(stl_cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_purity = 50  # Minimum percentage of ba to be occupied by one species\n",
    "df_stl[\"max_N_ln\"] = np.nan\n",
    "df_stl[\"formula\"] = \"\"\n",
    "df_stl[\"model\"] = \"\"\n",
    "\n",
    "avg_int = stl_lin.query(\"species_lat2 == 'Average'\")[\"intercept\"].values[0]\n",
    "avg_slo = stl_lin.query(\"species_lat2 == 'Average'\")[\"ln_D\"].values[0]\n",
    "\n",
    "for i in tqdm(range(df_stl.shape[0])):\n",
    "    # Get dominant species of plot\n",
    "    s = df_stl.at[i, \"dom_species_lat2\"]\n",
    "    dbh_sq = df_stl.at[i, \"dbh_1_sq\"]\n",
    "    purity = df_stl.at[i, \"ba_1_perc_of_species_lat2\"]\n",
    "    # If purity is not achieved, then go for averaged linear model\n",
    "    if purity < min_purity:\n",
    "        df_stl.at[i, \"max_N_ln\"] = avg_int + avg_slo * math.log(dbh_sq)\n",
    "        df_stl.at[i, \"formula\"] = f\"{avg_int} + {avg_slo} * math.log({dbh_sq})\"\n",
    "        df_stl.at[i, \"model\"] = \"avg_low_purity\"\n",
    "    else:\n",
    "        # If purity is achieved, check if curvilinear model is available:\n",
    "        if s in stl_cur.species_lat2.unique():\n",
    "            # Get parameters\n",
    "            inter = stl_cur.query(\"species_lat2 == @s\")[\"intercept\"].values[0]\n",
    "            slope_1 = stl_cur.query(\"species_lat2 == @s\")[\"ln_D\"].values[0]\n",
    "            slope_2 = stl_cur.query(\"species_lat2 == @s\")[\"ln_D2\"].values[0]\n",
    "            # Calculate max ln(N)\n",
    "            df_stl.at[i, \"max_N_ln\"] = (\n",
    "                inter + slope_1 * math.log(dbh_sq) + slope_2 * math.log(dbh_sq) ** 2\n",
    "            )\n",
    "            df_stl.at[i, \"formula\"] = (\n",
    "                f\"{inter} + {slope_1} * math.log({dbh_sq}) + {slope_2} * math.log({dbh_sq}) ** 2\"\n",
    "            )\n",
    "            df_stl.at[i, \"model\"] = \"curvilinear\"\n",
    "            # If curvilinear model is not available check if linear model for species is available\n",
    "        elif s in stl_lin.species_lat2.unique():\n",
    "            # Get parameters\n",
    "            inter = stl_lin.query(\"species_lat2 == @s\")[\"intercept\"].values[0]\n",
    "            slope_1 = stl_lin.query(\"species_lat2 == @s\")[\"ln_D\"].values[0]\n",
    "            # Calculate max ln(N)\n",
    "            df_stl.at[i, \"max_N_ln\"] = inter + slope_1 * math.log(dbh_sq)\n",
    "            df_stl.at[i, \"formula\"] = f\"{inter} + {slope_1} * math.log({dbh_sq})\"\n",
    "            # If linear model is not available for species, take average value\n",
    "            df_stl.at[i, \"model\"] = \"linear\"\n",
    "        else:\n",
    "            df_stl.at[i, \"max_N_ln\"] = avg_int + avg_slo * math.log(dbh_sq)\n",
    "            df_stl.at[i, \"formula\"] = f\"{avg_int} + {avg_slo} * math.log({dbh_sq})\"\n",
    "            df_stl.at[i, \"model\"] = \"avg_no_species\"\n",
    "\n",
    "# When done, take exponential of max_N to get number of trees\n",
    "df_stl[\"max_N\"] = df_stl[\"max_N_ln\"].apply(math.exp)\n",
    "# Add percentage of current / max N trees\n",
    "df_stl[\"carrying_capacity\"] = df_stl[\"num_trees_per_ha\"] / df_stl[\"max_N\"]\n",
    "# Add log ba\n",
    "df_stl[\"dbh_1_sq_log\"] = np.log(df_stl[\"dbh_1_sq\"])\n",
    "# Show df\n",
    "df_stl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some stats\n",
    "display(df_stl.describe())\n",
    "display(df_stl.groupby(\"model\")[\"max_N\"].describe())\n",
    "display(df_stl.value_counts(\"model\", normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore infinity warning, just future changes warning\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Set the style of the plot\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create a figure with multiple subplots\n",
    "fig, axes = plt.subplots(3, 2, figsize=(10, 10))\n",
    "\n",
    "# Plot density lines for quality control\n",
    "# max N ~ Model\n",
    "for model, group in df_stl.groupby(\"model\"):\n",
    "    sns.kdeplot(\n",
    "        group[\"max_N\"], ax=axes[0, 0], label=model\n",
    "    )  # Adjust other parameters as needed\n",
    "axes[0, 0].set_title(\"Calculated Max Number of Trees per Model Setup\")\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Purity ~ Model\n",
    "for model, group in df_stl.groupby(\"model\"):\n",
    "    sns.kdeplot(\n",
    "        group[\"ba_1_perc_of_species_lat2\"], ax=axes[0, 1], label=model\n",
    "    )  # Adjust other parameters as needed\n",
    "axes[0, 1].set_title(\"Purity per Model Setup\")\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# DBH ~ Model\n",
    "for model, group in df_stl.groupby(\"model\"):\n",
    "    sns.kdeplot(\n",
    "        group[\"dbh_1_sq\"], ax=axes[1, 0], label=model\n",
    "    )  # Adjust other parameters as needed\n",
    "axes[1, 0].set_title(\"Mean of DBH^2 per Model Setup\")\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# CC ~ Model\n",
    "for model, group in df_stl.groupby(\"model\"):\n",
    "    sns.kdeplot(\n",
    "        group[\"carrying_capacity\"], ax=axes[1, 1], label=model\n",
    "    )  # Adjust other parameters as needed\n",
    "axes[1, 1].set_title(\"Carrying Capacity per Model Setup\")\n",
    "axes[1, 1].legend()\n",
    "\n",
    "# STL - Scatterplot\n",
    "sns.scatterplot(\n",
    "    data=df_stl,\n",
    "    x=\"dbh_1_sq_log\",\n",
    "    y=\"max_N_ln\",\n",
    "    hue=\"model\",\n",
    "    palette=\"Set1\",\n",
    "    ax=axes[2, 0],\n",
    ")\n",
    "axes[2, 0].legend(title=\"Model\", loc=\"upper right\")\n",
    "\n",
    "# Estimated Max versus Current\n",
    "sns.kdeplot(\n",
    "    data=df_stl,\n",
    "    x=\"num_trees_per_ha\",\n",
    "    y=\"max_N\",\n",
    "    fill=True,\n",
    "    thresh=0.05,\n",
    "    levels=10,\n",
    "    cmap=\"mako\",\n",
    "    legend=True,\n",
    "    ax=axes[2, 1],\n",
    ")\n",
    "axes[2, 1].plot([0, 4000], [0, 4000], color=\"red\", linestyle=\"--\")\n",
    "axes[2, 1].set_xlim([0, 4000])\n",
    "axes[2, 1].set_ylim([0, 4000])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stl[[\"idp\", \"carrying_capacity\"]].to_feather(\n",
    "    \"../../data/final/predictor_datasets/forest_carrying_capacity.feather\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
